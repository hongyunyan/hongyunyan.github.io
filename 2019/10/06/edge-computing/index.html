<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="这是一个edge computing的research学习blog。 Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge ASPLOS 2017 University of Michigan  这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把">
<meta property="og:type" content="article">
<meta property="og:title" content="Edge Computing 论文阅读">
<meta property="og:url" content="http://yoursite.com/2019/10/06/edge-computing/index.html">
<meta property="og:site_name" content="Yunyan Hong">
<meta property="og:description" content="这是一个edge computing的research学习blog。 Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge ASPLOS 2017 University of Michigan  这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/1.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/2.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/3.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/5.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/4.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/6.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/7.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/9.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/8.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/10.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/11.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/12.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/13.png">
<meta property="og:updated_time" content="2019-10-28T13:42:25.243Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Edge Computing 论文阅读">
<meta name="twitter:description" content="这是一个edge computing的research学习blog。 Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge ASPLOS 2017 University of Michigan  这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把">
<meta name="twitter:image" content="http://yoursite.com/2019/10/06/edge-computing/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/10/06/edge-computing/">





  <title>Edge Computing 论文阅读 | Yunyan Hong</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yunyan Hong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/06/edge-computing/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="yunyan.hong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yunyan Hong">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Edge Computing 论文阅读</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-06T14:10:27+08:00">
                2019-10-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Research/" itemprop="url" rel="index">
                    <span itemprop="name">Research</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这是一个edge computing的research学习blog。</p>
<h3 id="Neurosurgeon-Collaborative-Intelligence-Between-the-Cloud-and-Mobile-Edge"><a href="#Neurosurgeon-Collaborative-Intelligence-Between-the-Cloud-and-Mobile-Edge" class="headerlink" title="Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge"></a>Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge</h3><ul>
<li>ASPLOS 2017</li>
<li>University of Michigan</li>
</ul>
<p>这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把所有数据传到云上去，然后让云做完计算，然后再传回设备。但是当我们传输的不是文本数据，而有视频数据、图片数据、语音数据等的时候，我们会发现这些数据量是非常大的，会带来传输压力，计算压力，能耗问题，云端吞吐等一系列问题。因此就希望能将部分计算推到边缘设备上。</p>
<p>文章的主要关注的是对DNN模型的端云协同计算，设计了Neurosurgeon，是一种轻量级调度程序，对DNN自动划分哪些层在端设备上做，哪些层在云上做。</p>
<p>作者先测试了一下目前仅在云上训练的情况，用AlexNet作为我们的试验DNN结构，然后用一张152kb的image来做inference，来测试了communication latency，computation latency， end-to-end latency和energy consumption。得到了下面的几点发现：</p>
<ul>
<li>数据传输延迟通常高于移动计算延迟，尤其是在3G和LTE上。</li>
<li>与移动处理相比，云处理具有显着的计算优势，但由于数据传输开销太大，从end-to-end的角度来说它并不是总是保持优势的。</li>
<li>与仅使用云的方法相比，本地移动执行通常会导致更低的延迟和能耗，而如果使用快速Wi-Fi连接，则仅云方法可实现更好的性能。</li>
</ul>
<p>然后作者分析了DNN中的每个层在数据量和计算的特性。包括了fully-connected layer, convolution&amp;local layer, pooling layer, activation layer, normalization layer, softmax layer, argmax layer, dropout layer等。</p>
<ul>
<li>conv和fc层占据了主要的计算时间，尤其是fc层， 移动GPU上的卷积和池化层的延迟相对较小，而完全连接的层导致高延迟。</li>
<li>前几个conv的数据量很大，后面的逐渐减少。</li>
<li>卷积和池化层主要位于网络的前端，而完全连接的层位于后端。</li>
<li>卷积层（convolution layer) 增加数据，然后池化层(pooling)减少数据，数据的大小是不断的在减少的。</li>
<li>数据大小从前到后不断减少，而从前往后看每层在设备上的计算延迟通常更高，这表明在设备和云之间的DNN中间的计算分区的独特机会。</li>
</ul>
<p>然后作者实验了在alexnet的每个层作为分层进行测试latency和energy，在alexnet使用GPU和WIFI的情况下，最佳的切分点在DNN的中间层。</p>
<p>然后作者把上面的发现，扩展到其他DNN上进行实验。发现划分DNN的最佳方法取决于网络的拓扑结构和组成层。 在CV领域，DNN的最佳分区点在网络中间，而对于ASR和NLPDNN网络，在开头或结尾划分则更有利。因此对于不同的网络而言，划分点都是不同的，因此我们需要一个能对不同网络自动化分切分点的机制。</p>
<p><img src="/2019/10/06/edge-computing/1.png" width="100%"></p>
<p>于是论文就提出了Neurosurgen这个系统，整个工作的流程是这样的：</p>
<ol>
<li>系统先分析提取DNN的架构，每层的类型和配置</li>
<li>然后系统用一个预测模型，来估计每层在云端和设备端的latency和energy consumption</li>
<li>根据上面预测的结果，结合网络带宽和云端负载情况，系统挑选出最合适的切分点。</li>
<li>然后就根据划分点，然后在划分点前由端设备计算，然后将最后一层的输出发送到云端，由云端完成后续的计算，再把结果发回给设备端。</li>
</ol>
<p>这边提到的预测模型，是根据已知的层参数和对应的latency，energy消耗来拟合作的一个对数回归函数。</p>
<p>最后，作者使用8个不同的DNN作为我们的基准，通过Wi-Fi，LTE和3G无线连接，仅支持CPU和GPU的端平台，来评估Neurosurgeon。进行了latency，energy，和MAUI架构的对比，对网络情况的适应性测试，对Server load变化适应性测试，和数据中心吞吐量的指标测评。</p>
<p>与仅云处理相比，神经外科医生在8个基准测试中实现了平均3.1倍和最高达40.7倍的连续加速，平均降低了59.5％和最高达94.7％的移动能耗，并提高了数据中心的吞吐量平均1.5倍，最高为6.7倍。</p>
<blockquote>
<p>吃饭的时候聊到说目前的网络大部分层的output的data size都是大于原有input的，所以其实如果要找到一层size比较小的情况然后发到云上，那一般在很后面的层了，不过好像后面的fc层的确是latency比较大的层，可能也是合理的吧。cq学长提到说，对这样的一部分在设备端，一部分在云上的，是不是应该考虑自己建一个网络，而不是用现有的网络进行分割。</p>
</blockquote>
<p><br></p>
<h3 id="Distributed-Deep-Neural-Networks-over-the-Cloud-the-Edge-and-End-Devices"><a href="#Distributed-Deep-Neural-Networks-over-the-Cloud-the-Edge-and-End-Devices" class="headerlink" title="Distributed Deep Neural Networks over the Cloud, the Edge and End Devices"></a>Distributed Deep Neural Networks over the Cloud, the Edge and End Devices</h3><ul>
<li>ICDCS 2017 (B)</li>
<li>Harvard University</li>
</ul>
<p>本文主要关注的也是end devices, edge和cloud协同进行对网络进行inference。主要的方法也是先在end devices算，然后end结束以后判断一下end算的符不符合confident，符合就直接作为结果返回，如果不足够，就把当前的结果作为输入输给edge，继续算剩下的layers，然后edge结束再进行新一轮判断，符合就作为结果返回，如果不够就再输给cloud算。【我的理解是整个end，edge，cloud的所有层拼起来是一个完整的DNN，仿佛是这个意思哈，整个是看能不能提前exit的意思，到时候看一下他引用的BranchyNet怎么做early exit的】。</p>
<p><img src="/2019/10/06/edge-computing/2.png" width="100%"></p>
<p>因为你的end device，或者是edge都可以是多个组成的，所以当他们各自算完以后，有一个aggregation的步骤，这边给出了三种方法，Max pooling，Average Pooling和Concatenation。</p>
<p>这边DDNN的training part我感觉我没有理解的很清楚，反正他说是根据BranchyNet的方法，所以到时候再说吧。这边有提到的是说</p>
<blockquote>
<p>to train the DDNN we form a joint optimization problem as minimizing a weighted sum of the loss functions of each exit.</p>
</blockquote>
<p>然后对于inference的exit的threshold，这边用的是求一个normalized entropy[虽然为什么用熵我也不是很了解2333]</p>
<p><img src="/2019/10/06/edge-computing/3.png" width="50%"></p>
<p>这边的测试选用的是6个end device，一个edge和一个cloud, 那六个device可以理解为一个交通口不同位置的摄像头，在抓拍照片，然后我们就是要识别这些抓拍到的照片里面的对象。发现多个device的时候，我们其实是相比单个device提高了精准度的，当device少的时候，更多的sample最后被扔到云上去后续计算了，而device增多的时候，在device本身能解决的sample也增多了。最后的threshold设为了0.8，这样达到最后overall 97的准确率，并有62%的sample没有被发到云上。</p>
<p>最后的结果反正就是说这样的做法准确率也很高，容错性也很好，也减少了传输的cost。 </p>
<p><br></p>
<h3 id="Big-Little-Deep-Neural-Network-for-Ultra-Low-Power-Inference"><a href="#Big-Little-Deep-Neural-Network-for-Ultra-Low-Power-Inference" class="headerlink" title="Big/Little Deep Neural Network for Ultra Low Power Inference"></a>Big/Little Deep Neural Network for Ultra Low Power Inference</h3><ul>
<li>CODES 2015（B）</li>
<li>Seoul National University + Samsumg</li>
</ul>
<p>这篇文章就是非常典型的大小网络，他认为说以图片分类为例，大部分的sample其实都用不到那么复杂的网络，只要一个简单的小一点的网络其实就能实现比较好的结果了，并且这些小的网络可以很大程度的节省energy。所以他就是提出说要先让sample跑小网络，然后跑完检测说这个结果靠谱么，如果靠谱就直接作为最终的结果，如果不靠谱就再扔到大网络里面去跑。</p>
<p><img src="/2019/10/06/edge-computing/5.png" width="80%"></p>
<p>对于这个区分靠谱不靠谱，这边给出的想法是用一个score margin来作为指标。score margin这边给的是1st score - 2st score. 感觉作为一个分类问题，这样的设计方法还是蛮合理当然也很直观233.【感觉大小网络的一个研究点不就在于怎么判断我小网络的结果是可以的，不需要大网络来算了么】然后对于这个score margin，我们再设定一个阈值，如果大于阈值，我就认为我相信这个结果，如果小于，那就扔到大网络里面去。</p>
<p>然后对于这个挑阈值的问题，这边给出了两个方法，一个是固定的threshold，一个是dynamic调整threshold。</p>
<ul>
<li><p>static Threshold的想法是说，我一个比较好的threshold是一方面可以尽可能少的用到大网络，另一个是我要减少loss of inference accuracy。所以就在这两个方向做tradeoff，来获得一个合适的threshold值</p>
</li>
<li><p>dynamic threshold的想法是说，首先我将整个问题转化为最大化下面这个式子，这边原来想最大化的是P(correct)，但是我们认为这个其实可以认为是下面这个和网络算出来的score margin线性相关的，所以就用下一个式子来表示【因为P也不好算嘛】【当然其实这个要是等价，首先的前提就是说score margin决定结果是不是对的这个想法是可信的，这个part我具体没有了解过，是不是这样靠谱的。】然后那我要最大化下面这个式子，我怎么来找到合适的threshold的呢？这边作者给出的方法比较直接，我先初始化$Theta$和$\Delta$,然后每次我们比较threshold取$Theta$和$Theta + Delta$的下面这个式子的结果大小，如果$Theta$比较好，那就继续用这个，然后调整$Delta$,如果是后者比较好，就调整为后者，然后也调节一下$Delta$，整个过程就是一个梯度感觉。</p>
<p><img src="/2019/10/06/edge-computing/4.png" width="70%"></p>
</li>
</ul>
<p>然后这边实验部分还提到了一个对应做了一个hardware accelerator来处理，这个part没有太了解懂，也不是很重要吧，先放一放。然后作者在MNIST和ImageNet两个数据集上做了测试，来验证自己的想法是work的，还比较了不同小网络的结果。另外还比较了SRAM size的大小对energy的影响，在一定程度下，SRAM增大，energy consumption就会降低，因为SRAM增大，减少了off-chip DRAM access.</p>
<p><br></p>
<h3 id="The-Cascading-Neural-Network-Building-the-Internet-of-Smart-Things"><a href="#The-Cascading-Neural-Network-Building-the-Internet-of-Smart-Things" class="headerlink" title="The Cascading Neural Network: Building the Internet of Smart Things"></a>The Cascading Neural Network: Building the Internet of Smart Things</h3><ul>
<li>KNOWLEDGE AND INFORMATION SYSTEMS(B 会) 2017</li>
</ul>
<p>这篇文章感觉创新点没啥，主要的想法就是在一个网络里面，可以每层都直接接一个softmax，然后来判断是不是已经够了，不用继续往后面训练了。反正就是一个网络里面切出多个part，每个part结束都连一个softmax，然后判断现在的结果达标了么，没达标继续，达标了就结束。判断好没好，是选了softmax结果里面的max值是不是大于了阈值。这边说的网络的训练，可以直接先以传统的方式训练本身的网络，然后再保留每个层的中间结果，去训每层外接的softmax的参数就可以了。</p>
<p><br></p>
<h3 id="Edge-Intelligence-Paving-the-Last-Mile-of-Artificial-Intelligence-with-Edge-Computing"><a href="#Edge-Intelligence-Paving-the-Last-Mile-of-Artificial-Intelligence-with-Edge-Computing" class="headerlink" title="Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing"></a>Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing</h3><p>一篇edge intelligence的综述文章，中文翻译链接<a href="http://tongtianta.site/paper/46983" target="_blank" rel="noopener">http://tongtianta.site/paper/46983</a></p>
<p><br></p>
<h3 id="BranchyNet-Fast-Inference-via-Early-Exiting-from-Deep-Neural-Networks"><a href="#BranchyNet-Fast-Inference-via-Early-Exiting-from-Deep-Neural-Networks" class="headerlink" title="BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks"></a>BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks</h3><ul>
<li>2017</li>
<li>Harvard U</li>
</ul>
<p>一篇exit early的很有名的paper, 在网络里面插多个exit点。这篇文章讲了他怎么train 整个带exit的网络，首先用原始的网络训练完的参数初始化这个带exit的网络，然后再train这个新的网络，loss是带权重的每个exit处的loss function的累加和，带权重是指前面的exit branch的权重高，后面的exit branch的权重低。</p>
<p>这篇文章网络的结果是不仅时间短了，而且我看数据，三个网络里面的两个网络的acc也是比原有网络提升了0.几个点的。感觉很有意思。</p>
<p>文章里面提到的几个观点和解释也很有意思：</p>
<ul>
<li>因为有部分sample在inference时候是在提前退出的，所以说做bp的时候layer层比较少，这样就更可以抓到discriminative的features【感觉这就很神奇啊，也就是说层数少的网络可以抓住更重要的feature，但是层数多的网络可能能更全面的进行计算？】</li>
<li>exit point就像提供了一种正则化，来避免很多sample被overfit，所以提高了acc。</li>
</ul>
<p><br></p>
<blockquote>
<p>论文读到现在的感受：</p>
<ul>
<li>首先大家的目标其实是找到一个网络可以算的更快【所以说直接目标不是要他多小，主要想的是让他算的快】</li>
<li>然后大家很大部分的方法是，当我觉得我目前几层算的够了，我就提前退出。然后这个怎么提前退出，有的人一个网络设一个early exit点，有的设好几个，有的是只在conv层后面设。一般都是加个softmax层，这样根据他softmax的结果来算他的sc，根据threshold来判断能否退出。</li>
<li>感觉大家做的很没有创意啊…所有的论文感觉都是同一个思想，除了exit点设计的不一样，都没有更改判断是否exit的方式。</li>
<li>说到大小网络的话，其实做的人很少，大小网络的话，就是一个小网络算完判断是否ok，不ok继续大网络计算，然后他的ok不ok还是sc来判断。然后应用的话一般都是小网络放device上，大网络放云端吧。</li>
<li>不过这边的提出其实也不是专门针对edge的问题的。</li>
<li>大家说的都是inference的时候用这些，没有边训练边调整模型的。好像目前就没有说如何在设备端做training的。</li>
<li>奥目前的压缩网络好像就不能真实实际的减少计算时间，因为没有对应的算子保证？，那些置0的weight还是会被计算到，所以现在的压缩还是在模拟层面的？</li>
<li>感觉那个判断是否confident的不就是那个approximate网络里面的predictor么？为什么都不用网络做，是因为目的是减少计算时间，所以用一个网络过于慢了吗？</li>
<li>感觉应该看一下那个online learning那种的思想么？学习边做边调整 ?</li>
<li>还有的就是用近似网络来近似复杂的算法，用一个predictor来判断这个数据能不能近似，然后再来用近似网络进行近似。</li>
<li>感觉就两种方法– 一种就是先根据input来判断能不能用小网络来替换大网络，另一种就是说根据小网络结果来判断是不是需要大网络重新算。</li>
<li>我们现在要想的是考虑云端和设备端的协同，我们有哪些可以做的事情，而不是单单考虑说如何在设备端加速神经网络速度，来适配设备端的需求。感觉眼界可以再放大一点。目前有的<ul>
<li>神经网络加速</li>
<li>神经网络根据数据分布调整，就可以选取全模型中 对当前数据分布比较重要的point来调整小网络。</li>
</ul>
</li>
</ul>
</blockquote>
<p><br></p>
<h3 id="distilling-the-Knowledge-in-a-Neural-Network"><a href="#distilling-the-Knowledge-in-a-Neural-Network" class="headerlink" title="distilling the Knowledge in a Neural Network"></a>distilling the Knowledge in a Neural Network</h3><ul>
<li>2015</li>
<li>Hinton, Google</li>
</ul>
<blockquote>
<p>因为这篇文章实在是太火了，所以这边会摘取各位朋友对这篇文章的理解和分析。</p>
</blockquote>
<p>知识蒸馏的motivation：</p>
<blockquote>
<p>Knowledge Distill是一种简单弥补分类问题监督信号不足的办法。传统的分类问题，模型的目标是将输入的特征映射到输出空间的一个点上，例如在著名的Imagenet比赛中，就是要将所有可能的输入图片映射到输出空间的1000个点上。这么做的话这1000个点中的每一个点是一个one hot编码的类别信息。这样一个label能提供的监督信息只有log(class)这么多bit。然而在KD中，我们可以使用teacher model对于每个样本输出一个连续的label分布，这样可以利用的监督信息就远比one hot的多了。另外一个角度的理解，大家可以想象如果只有label这样的一个目标的话，那么这个模型的目标就是把训练样本中每一类的样本强制映射到同一个点上，这样其实对于训练很有帮助的类内variance和类间distance就损失掉了。然而使用teacher model的输出可以恢复出这方面的信息。具体的举例就像是paper中讲的， 猫和狗的距离比猫和桌子要近，同时如果一个动物确实长得像猫又像狗，那么它是可以给两类都提供监督。综上所述，KD的核心思想在于”打散”原来压缩到了一个点的监督信息，让student模型的输出尽量match teacher模型的输出分布。其实要达到这个目标其实不一定使用teacher model，在数据标注或者采集的时候本身保留的不确定信息也可以帮助模型的训练。</p>
</blockquote>
<p>文章的蒸馏方法主要是依靠soften了softmax的prob来实现的。以MINST为例，比如teacher net识别这个图片是2的概率为0.99，为3的概率为0.01，为7的概率为0.0001。那我的student的网络如何能学到除了这张图应该识别为2的知识呢？也就是要学到自己在对这张图片做softmax的时候，为3的概率应该也是比7大的。所以这边就提出了soften（也就是升温）</p>
<p>传统的softmax函数为$q_i = \frac{exp(zi)}{\sum_j exp(z_i) }$，我这边通过升温以后使他变为$q_i = \frac{exp(zi / T)}{\sum_j exp(z_i/T) }$。也就是说原来除以1，现在除以一个比1大的数，这样让每个softmax的值之间差距缩小。然后我们用这个soften的softmax prob作为student学习的一个soft target，传统的label产生的交叉熵作为hard target ，soft target和hard target一起指导student net学习。</p>
<p>实验部分，作者使用了MNIST进行图片分类的实验，一个有趣的地方在于（和论文前半部分举的2和3识别的例子呼应），作者在数据集中有意地去除了标签为3的样本。没有KD的student网络不能识别测试时候提供的3的数字，有KD的student网络能够识别一些3（虽然它从来没有在训练样本中出现过！）。后面，作者在语音识别和一个Google内部的很大的图像分类数据集（JFT dataset）上做了实验。</p>
<p>论文的另一个部分是集成模型，训练大数据集的一个简单方法是集成模型（将数据分成数个子集，分别训练然后集成），这种方法很容易并行化，但是却在测试的时候需要耗费大量的计算资源，而distillation可以解决这个问题。集成的一个主要问题是容易过拟合，这里也是利用soft targets的思想来处理这个问题，通过KL散度约束新模型与全体及分别的概率分布比较相似。</p>
<p>soft target还能用于避免overfit，避免模型的过度训练。</p>
<blockquote>
<p>突然觉得这个集成模型，不是很像我们实际应该分散在每个edge上的设备么?云端应该是那个general的net，然后edge是那个special的net。</p>
</blockquote>
<p><br></p>
<p>两篇近似网络的前文:</p>
<h3 id="Neural-Acceleration-for-General-Purpose-Approximate-Programs-2012"><a href="#Neural-Acceleration-for-General-Purpose-Approximate-Programs-2012" class="headerlink" title="Neural Acceleration for General-Purpose Approximate Programs(2012)"></a>Neural Acceleration for General-Purpose Approximate Programs(2012)</h3><h3 id="Prediction-Based-Quality-Control-for-Approximate-Accelerators-2015"><a href="#Prediction-Based-Quality-Control-for-Approximate-Accelerators-2015" class="headerlink" title="Prediction-Based Quality Control for Approximate Accelerators(2015)"></a>Prediction-Based Quality Control for Approximate Accelerators(2015)</h3><p>第一篇文章提出了我们能用神经网络来近似诸多函数。我们应当先选择合适的code部分来近似，要求这些code有固定size的input和固定size的output，这样才能保证我近似的神经网络输入输出的size是固定的。然后对于选择网络来拟合，这边首先是限定了能选择的网络拓扑结构的选择范围（比如隐层有1-2层，节点数最多是多少个），然后在训练各个拓扑下的网络，最后选择一个最好的网络，作为我们的近似网络。</p>
<p>第二篇文章提出了说我们不应该只有一个近似网络，我们还需要一个predictor来判断当前的输入适不适合用我们的近似网络进行近似，如果适合近似，我们才用我们的近似网络来计算，如果不适合，我们就用原来的code来计算。这边提出的predictor有两种类型，一种是table-based，另一种是network的。这边就是根据我能接受的最大的error diff来训练我的predictor。我觉得这边比较好的检验方法应该是比较每个获得的predictor的判断正确程度？论文里没有提到如何比较。</p>
<p><br></p>
<h3 id="Born-Again-Neural-Networks"><a href="#Born-Again-Neural-Networks" class="headerlink" title="Born-Again Neural Networks"></a>Born-Again Neural Networks</h3><ul>
<li>2018 ICML</li>
<li>南加州</li>
</ul>
<p>这篇文章的主要思想是下图的结构。也就是我先有一个teacher网络，然后用teacher网络去初始化第一个student网络，然后学生网络以预测正确标签，与教师输出分布相匹配这两个目标来进行训练。然后第一个student网络收敛后，就用它的参数去初始化下一个student网络，这样依次训练。最后把所有的student network集合起来作为我们的ensemble network，发现他的效果好于teacher网络。【但是这样多个net不是很占内存啥的么？速度也不快？所以是不是和原有的目标有违背?】奥好像是说他测试的时候会选这一群训出来的最后一个network来作为我们的BAN网络，和teacher网络进行比较。</p>
<p>另外他还提到可以用不同的拓扑结构的teacher网络辅导别的架构的student网络进行学习提升。</p>
<p><img src="/2019/10/06/edge-computing/6.png" width="100%"></p>
<p><br></p>
<h3 id="Rocket-Launching-A-Universal-and-Efficient-Framework-for-Training-Well-performing-Light-Net"><a href="#Rocket-Launching-A-Universal-and-Efficient-Framework-for-Training-Well-performing-Light-Net" class="headerlink" title="Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net"></a>Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net</h3><ul>
<li><p>2018 AAAI</p>
</li>
<li><p>清华 + 阿里</p>
<p>文章提出了一个新的方法来得到轻量的网络。下图是网络的结构，大小网络share了前n层网络的参数，并且他们是一起training的，因为作者认为小网络不仅仅要学习最后的结果，还要学习大网络学习的过程。对于整个网络的loss则为两个网络各自的cross-entropy以及l(x)和z(x)之间hint函数的。</p>
<p><img src="/2019/10/06/edge-computing/7.png" width="50%"></p>
<p>网络中l(x)和z(x)之间hint函数，作者给出了几种函数。（有些是q(x)和p(x)，就是softmax前或者softmax后）</p>
<p><img src="/2019/10/06/edge-computing/9.png" width="60%"></p>
<p>另外考虑到如果上面提到的网络的三个loss对两个网络一起调整参数，会导致大网络被小网络的质量影响，因此网络的bp中，对应的loss情况如下。也就是大网络只受自己的cross-entropy影响，另两个函数都用于调整小网络。</p>
<p><img src="/2019/10/06/edge-computing/8.png" width="50%"></p>
<p>作者最后发现，这样可以加快训练速度，并且让light net有更好的表现。</p>
</li>
</ul>
<p><br></p>
<h3 id="Collaborative-Learning-between-Cloud-and-End-Devices-An-Empirical-Study-on-Location-Prediction"><a href="#Collaborative-Learning-between-Cloud-and-End-Devices-An-Empirical-Study-on-Location-Prediction" class="headerlink" title="Collaborative Learning between Cloud and End Devices: An Empirical Study on Location Prediction"></a>Collaborative Learning between Cloud and End Devices: An Empirical Study on Location Prediction</h3><ul>
<li>SEC 2019</li>
<li>MSRA + 清华</li>
</ul>
<p>这篇文章讲的是，在以前的方法里面都是云端给device端提供一个小网络，供其使用，就结束了，小网络没有根据自己的数据进行新的迭代，这样对于device中不同的数据分布，原有的固定的小网络没有办法达到一个非常好的结果水平。</p>
<p>因此这边就提出说能不能让我们在device端不断inference的时候，并且用这些数据来调整自己device上的网络呢。所以这边就提出说我希望通过协同学习的方法来不断的提升network的效果。</p>
<p><img src="/2019/10/06/edge-computing/10.png" width="100%"></p>
<p>上图显示了这个协同学习的过程图。</p>
<ol>
<li>首先云端根据原有的数据训练了第一个model。</li>
<li>当一个device新加入这个系统后，云端会把最新的的云端模型压缩成一个小网络发给device。然后在接下来的一个时间段里面device就用这个小网络进行inference。</li>
<li>在过一段时间以后，device端会根据云端最新的网络，根据KD的思想，更新自己的网络。</li>
<li>然后根据device们最新的network，来指导云端的网络进行KD的学习，获得新的网络数据。</li>
<li>3和4不断的迭代发生，不停地对网络进行训练和提升。</li>
</ol>
<p>当device数量很多的时候，云端单独一个的network没有办法满足所有device的需求，所以就根据聚类，提供K个network提供给n个device，进行对应的KD调整。这边所有的KD的loss函数都是比较基础的函数，soft target + hard target一起进行指导。</p>
<p>【这边提到说device training是全部在device上完成的？所以就很好奇怎么搞的？？？】</p>
<p><br></p>
<h3 id="MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications"><a href="#MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications" class="headerlink" title="MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"></a>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</h3><ul>
<li>2017 Google</li>
</ul>
<p>文章解析见<a href="https://www.jiqizhixin.com/graph/technologies/c0bc9a32-bd3d-4df2-b0de-c433419a19e6" target="_blank" rel="noopener">https://www.jiqizhixin.com/graph/technologies/c0bc9a32-bd3d-4df2-b0de-c433419a19e6</a></p>
<h3 id="ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices"><a href="#ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices" class="headerlink" title="ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"></a>ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</h3><ul>
<li>2017 Face++</li>
</ul>
<p>文章解析见<a href="https://zhuanlan.zhihu.com/p/32304419" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32304419</a></p>
<h3 id="ThiNet-A-Filter-Level-Pruning-Method-for-Deep-Neural-Network-Compreesion"><a href="#ThiNet-A-Filter-Level-Pruning-Method-for-Deep-Neural-Network-Compreesion" class="headerlink" title="ThiNet: A Filter Level Pruning Method for Deep Neural Network Compreesion"></a>ThiNet: A Filter Level Pruning Method for Deep Neural Network Compreesion</h3><ul>
<li>ICCV 2017</li>
</ul>
<p>文章解析见<a href="https://blog.csdn.net/wspba/article/details/77427960" target="_blank" rel="noopener">https://blog.csdn.net/wspba/article/details/77427960</a> 和 <a href="https://blog.csdn.net/u014380165/article/details/77763037" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/77763037</a></p>
<p><br></p>
<h3 id="Snapshot-Distillation-Teacher-Student-Optimization-in-One-Generation"><a href="#Snapshot-Distillation-Teacher-Student-Optimization-in-One-Generation" class="headerlink" title="Snapshot Distillation: Teacher-Student Optimization in One Generation"></a>Snapshot Distillation: Teacher-Student Optimization in One Generation</h3><ul>
<li>2019 CVPR</li>
<li>Johns Hopkins U</li>
</ul>
<p>这篇文章是一篇Teacher-Studenet模型的优化工作。这边提出的是觉得一方面目前在BAN提出后，这个多个studenet一个个训练下去，时间成本非常高，需要k×base model的时间。因此他就认为，我能不能每个老师不是我每个iteration结束时候的network，而是我们在每个epochs结束时候就选取当前的网络为新的teacher进行计算，来缩短时间。</p>
<p>这边要这样训练有三点需要满足：</p>
<ol>
<li>teacher 的network应该要有比较好的质量</li>
<li>teacher和student需要有差异。【所以这边采用的是每个min-batch里面用从大变小的learning rate来收敛。但teacher和student到底差不差一代，没看懂233，也非常好奇】</li>
<li>需要加强secondary信息的传递。【也就是一个dark knowledge的概念，我们不仅要学绝对的那个标准，还要学跟他相似的其他类信息，所以说他这边用loss函数抑制了前面的teacher的top1的百分比，让后续的学生更好的学习】</li>
</ol>
<p><br></p>
<h3 id="SeerNet-Predicting-Convolutional-Neural-Network-Feature-Map-Sparsity-through-Low-Bit-Quantization"><a href="#SeerNet-Predicting-Convolutional-Neural-Network-Feature-Map-Sparsity-through-Low-Bit-Quantization" class="headerlink" title="SeerNet: Predicting Convolutional Neural  Network Feature-Map Sparsity through Low-Bit Quantization"></a>SeerNet: Predicting Convolutional Neural  Network Feature-Map Sparsity through Low-Bit Quantization</h3><ul>
<li>cvpr 2019</li>
<li>MSRA</li>
</ul>
<p>文章主要的思想是说，我先用一个很小的bit量，比如1,2,4来计算我feature map和weight的结果，来判读我输出时候哪些值是有用的（因为relu和max-pooling会让大部分的计算都作废了），然后根据算出来真实会被选用的那些位置，去进行精确的计算，来节省计算量。【每一层都先预测，然后真实计算】</p>
<p>并且文章提出利用AVX加速，并且通过保存非0值的column和row坐标来表示feature map,来进行软硬层结合的加速。</p>
<p><br></p>
<h3 id="GOOGLE-Federated-Learning-Papers"><a href="#GOOGLE-Federated-Learning-Papers" class="headerlink" title="GOOGLE Federated Learning Papers:"></a>GOOGLE Federated Learning Papers:</h3><h5 id="Applied-Federated-learning-Improving-Google-Keyborad-Query-Suggestions"><a href="#Applied-Federated-learning-Improving-Google-Keyborad-Query-Suggestions" class="headerlink" title="Applied Federated learning: Improving Google Keyborad Query Suggestions"></a>Applied Federated learning: Improving Google Keyborad Query Suggestions</h5><h5 id="Federated-Learning-For-Mobile-Keyboard-Prediction"><a href="#Federated-Learning-For-Mobile-Keyboard-Prediction" class="headerlink" title="Federated Learning For Mobile Keyboard Prediction"></a>Federated Learning For Mobile Keyboard Prediction</h5><h5 id="Federated-Learning-Of-Out-Of-Vocabulary-Words"><a href="#Federated-Learning-Of-Out-Of-Vocabulary-Words" class="headerlink" title="Federated Learning Of Out-Of-Vocabulary Words"></a>Federated Learning Of Out-Of-Vocabulary Words</h5><h5 id="Towards-Federated-Learning-At-Scale-System-Design"><a href="#Towards-Federated-Learning-At-Scale-System-Design" class="headerlink" title="Towards Federated Learning At Scale: System Design"></a>Towards Federated Learning At Scale: System Design</h5><p>这几篇文章主要就是讲了目前google利用联邦学习做的一些应用提升的尝试，包括了keyword的query，prediction等。主要的方法都是说当设备符合充电且连wifi的前提条件，并且满足的数量达到我们的threshold后，从这些满足条件的设备中选取一些设备，发给我们云端目前的模型checkpoint，让他们用自己本地的数据训练这些模型，然后训练后把模型参数返回，然后云端federated Average处理后，生成新的云端模型，并把模型传到device上，作为他们的新model。目前对不同的设备的不同dataset量，用了加权的方法来平衡不同的贡献。</p>
<p>还有的一些问题包括了：</p>
<ul>
<li>convergence time </li>
<li>Bias</li>
<li>Bandwidth</li>
<li>Device Scheduling</li>
</ul>
<p><br></p>
<h3 id="In-situ-AI-Towards-Autonomous-and-Incremental-Deep-Learning-for-IoT-Systems"><a href="#In-situ-AI-Towards-Autonomous-and-Incremental-Deep-Learning-for-IoT-Systems" class="headerlink" title="In-situ AI : Towards Autonomous and Incremental Deep Learning for IoT Systems"></a>In-situ AI : Towards Autonomous and Incremental Deep Learning for IoT Systems</h3><ul>
<li>HPCA 2018</li>
<li>弗洛里达大学，litao老师组</li>
</ul>
<p>这篇文章主要画了个框架的饼，跟我们做的应该是非常相关的。</p>
<p>首先他提出了目前Iot面临的问题，比如实际使用中，噪音很重，很好的网络并不能很好的适应当前的状况；很多数据没有标注，也难以全部标注。然后我们要减少device到cloud的movement，然后又要低延时低energy损耗。然后他就提出了一个框架，实现automonous and incremental 学习。</p>
<p>这个框架的背景应用在要识别图像，异常检测、分类等。他提出的框架如下。</p>
<p><img src="/2019/10/06/edge-computing/11.png" width="80%"></p>
<p>首先他是说，我们先来做一个无监督的问题，把一张图片切成九块，然后打乱顺序，让网络来判断这九张图真实的相对顺序。然后他说这个网络是和我们上面提到的图片识别啊，异常检测，分类问题啊都非常相关的。并且前面基层的数据就是来抓取图片的特征的，我们可以通过这个无监督的网络前几层来帮助后面的那个inference网络提高acc，就类似一个pretrain的工作。</p>
<p>然后在上面那个无监督的网络（也叫diagnosis net)train的差不多了，就用少数有label的数据去train inference 的network，然后就得到一个inference net。然后我们把这两个都扔到device上去。然后对于实际拿到的图片，我们先通过diagnosis net，如果他识别顺序正确，我们就拿去做inference，如果不对，我就把他扔回去cloud，来调我的无监督模型，然后因为他们前面几层的参数是共享的，所以后面也会调整inference（猜测是用原有有label的数据继续辅助调整）。然后这样就是一个incremental的过程。</p>
<blockquote>
<p>这边这个无监督很好的解决了一个incremental的问题，可以参考应用一下，不然的确没法解决这个没有label的问题。然后这边的cloud和edge用的是同样的模型，不存在大小的问题。</p>
<p>当然学长说了这可能只是个饼，很难work。</p>
</blockquote>
<p><br></p>
<h3 id="新的思考part"><a href="#新的思考part" class="headerlink" title="新的思考part"></a>新的思考part</h3><p>端云协同需要决定的问题：</p>
<ol>
<li>你的端和云是要用一个网络么，还是大网络、小网络<ol>
<li>如果是大小网络，怎么指导学习呢，只能自己学习？</li>
<li>一个网络可以一起学习，可是那为啥还要你小网络的存在呢？</li>
</ol>
</li>
<li>你的端云的网络要不断的学习么，要incremental么<ol>
<li>如果要不断的学习，data没有标注怎么办<ol>
<li>无监督</li>
<li>大网络指导小网络</li>
</ol>
</li>
<li>如果不学习，那做啥优化呢？<ol>
<li>如果是大小网络，就是来判断我啥时候要用大网络？然后我咋调整小网络？</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><br></p>
<h3 id="Task-Adaptive-Incremental-Learning-for-Intelligent-Edge-Devices"><a href="#Task-Adaptive-Incremental-Learning-for-Intelligent-Edge-Devices" class="headerlink" title="Task-Adaptive Incremental Learning for Intelligent Edge Devices"></a>Task-Adaptive Incremental Learning for Intelligent Edge Devices</h3><ul>
<li>george mason U</li>
<li>最近新在arxiv上的一个2页的短文，感觉写的也很水，也没有说具体的技术细节，就画了个饼，可能到时候要扩展去投啥把，但是思想是和上次聊到的非常像。</li>
</ul>
<p>主要的思想就是说，我云端是各模型，然后我的device端是一个special的网络，针对各自的特点的网络。然后他认为special的网络是将云端的网络分成两个part以后组成的，就云端的网络前几层作为一个shared layers，每个special网络都共用这个shared layers，然后在后面几层可以decouple成多个critical path。然后device端只具有自己针对类别的critical path组成的网络，然后根据自己的数据微调。然后每个device把自己critical path调整的参数传给cloud，更改云端模型。</p>
<p><img src="/2019/10/06/edge-computing/12.png" width="80%"></p>
<p>他还能增加新的分类critical path，非常的迷惑了。</p>
<p>当然怎么分critical path不知道，怎么知道对应哪个device要用哪几个critical path，不知道，为什么能新增path，不知道。疯狂挠头？所以也不知道是个纯饼还是只是展示了部分工作。思路还是比较明显的，就是感觉这几个技术点还是不好解决的。</p>
<p><br></p>
<h3 id="Distilling-Critical-Paths-in-Convolutional-Neural-Networks"><a href="#Distilling-Critical-Paths-in-Convolutional-Neural-Networks" class="headerlink" title="Distilling Critical Paths in Convolutional Neural Networks"></a>Distilling Critical Paths in Convolutional Neural Networks</h3><ul>
<li>楼上文章的组，发在nips的workshop里面，是一篇短文，算是上面一篇文章的前序文章</li>
</ul>
<p>文章讲的就是如何找到CNN的critical path，来针对的distill。这边用的是mean absolute activation + contribution index + AM visualization三种思想。</p>
<p>在distill critical path中，他们首先选择前多少层是basic，不用挑选critical path的。然后计算每层的mean absolute activation、contribution index，把他们的结果相乘来选择filter。根据我们设定的reserved ratio来决定我们能选择多少个filters。另外因为抽取了filter，会改变最后logit层的情况，所以就是被删掉的其他class的logit对应会置为0。</p>
<p><br></p>
<h3 id="Orchestrating-Development-Lifecycle-of-Machine-Learning-Based-IoT-Applications-A-Survey"><a href="#Orchestrating-Development-Lifecycle-of-Machine-Learning-Based-IoT-Applications-A-Survey" class="headerlink" title="Orchestrating Development Lifecycle of Machine Learning Based IoT Applications: A Survey"></a>Orchestrating Development Lifecycle of Machine Learning Based IoT Applications: A Survey</h3><p>文章的整体架构如下图所示。<br>model Development 讲的是根据你IoT的需求找一个对应的model，并且根据设备的情况优化model，并选用对应的框架来把生成模型。</p>
<ol>
<li>模型本身分为三类，传统的机器学习方法，deep learning和reinforcement learning。一般就data量少的，追求轻量级的找TML，有比较多交互的用RL，别的用DL。 在DL中，AE可以用于异常检测或者预处理，GAN则可以用来增加一些samples。</li>
<li>在model generation部分，主要提及的是加速的问题，一般通过优化并行，data parallel或者model parallel来帮助加速。另外就是在Distributed的ML系统中，目前的update strategy用的倾向于异步的系统，且支持有掉队者，并且利用过时的思想来保证update的正确性。</li>
<li>在模型优化中，一方面是进行特征处理，在诸多数据中去除冗余数据，筛选重要的feature，来帮助优化模型。另外的是为了适配device的实际算力，一般会有几种处理方式，一种是针对这些小算力设备提出特殊的模型，比如MobileNet等，另一种是NAS，来搜索匹配合适的network，另一个则是模型压缩，包括剪枝、低秩分解，压缩的卷积filter，知识蒸馏等。</li>
<li>模型评估这边就比较基本了，就是用tp,fp,tn,fn,precison,recall,F1,mse,mae,mpe等这些指标来衡量模型。</li>
</ol>
<p>Model Deployment上，说实在的，不知道他在写啥，大概就是在将我把挑好的模型部署到实际的场景中，还会有对应哪些操作需要进行优化，来符合我的延迟、resource，storage，memory, output等情况。为了应对各种实际场景下的问题，提出了一些方法【总的来说不知道在说啥】</p>
<p>Model Audit就是在评估实际的应用中有没有有效安全可信的进行运作，安全方面介绍了一些攻击类型，提出应该构建怎么样的安全的平台或者框架，然后又提到关于fault tolerance的问题，要增强generalization的能力，包括正则化，增加data，提前退出等。以及在我们考虑一个模型的表现中，需要考虑model的precision，execution latency, bandwidth usage, resource Consumption和system throughput。</p>
<p>Model Acquisition部分就说了对数据的收集，数据的处理， 以及数据的融合处理。</p>
<p><img src="/2019/10/06/edge-computing/13.png" width="100%"></p>
<blockquote>
<p>【感觉不知道是自己没有抓住重点还是怎么回事，感觉这篇survey比较普通吧，更多的感觉侧重在了分布式的一些内容上?感觉对IoT方面的叙述没有那么全面把？其实主要是也不知道怎么判断一篇survey写的好不好23333</p>
</blockquote>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/22/Cloud/" rel="next" title="云相关知识">
                <i class="fa fa-chevron-left"></i> 云相关知识
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
     <div id="gitalk-container"></div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">yunyan.hong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Neurosurgeon-Collaborative-Intelligence-Between-the-Cloud-and-Mobile-Edge"><span class="nav-number">1.</span> <span class="nav-text">Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distributed-Deep-Neural-Networks-over-the-Cloud-the-Edge-and-End-Devices"><span class="nav-number">2.</span> <span class="nav-text">Distributed Deep Neural Networks over the Cloud, the Edge and End Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Big-Little-Deep-Neural-Network-for-Ultra-Low-Power-Inference"><span class="nav-number">3.</span> <span class="nav-text">Big/Little Deep Neural Network for Ultra Low Power Inference</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Cascading-Neural-Network-Building-the-Internet-of-Smart-Things"><span class="nav-number">4.</span> <span class="nav-text">The Cascading Neural Network: Building the Internet of Smart Things</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Edge-Intelligence-Paving-the-Last-Mile-of-Artificial-Intelligence-with-Edge-Computing"><span class="nav-number">5.</span> <span class="nav-text">Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BranchyNet-Fast-Inference-via-Early-Exiting-from-Deep-Neural-Networks"><span class="nav-number">6.</span> <span class="nav-text">BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#distilling-the-Knowledge-in-a-Neural-Network"><span class="nav-number">7.</span> <span class="nav-text">distilling the Knowledge in a Neural Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Acceleration-for-General-Purpose-Approximate-Programs-2012"><span class="nav-number">8.</span> <span class="nav-text">Neural Acceleration for General-Purpose Approximate Programs(2012)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prediction-Based-Quality-Control-for-Approximate-Accelerators-2015"><span class="nav-number">9.</span> <span class="nav-text">Prediction-Based Quality Control for Approximate Accelerators(2015)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Born-Again-Neural-Networks"><span class="nav-number">10.</span> <span class="nav-text">Born-Again Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Rocket-Launching-A-Universal-and-Efficient-Framework-for-Training-Well-performing-Light-Net"><span class="nav-number">11.</span> <span class="nav-text">Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Collaborative-Learning-between-Cloud-and-End-Devices-An-Empirical-Study-on-Location-Prediction"><span class="nav-number">12.</span> <span class="nav-text">Collaborative Learning between Cloud and End Devices: An Empirical Study on Location Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications"><span class="nav-number">13.</span> <span class="nav-text">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices"><span class="nav-number">14.</span> <span class="nav-text">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ThiNet-A-Filter-Level-Pruning-Method-for-Deep-Neural-Network-Compreesion"><span class="nav-number">15.</span> <span class="nav-text">ThiNet: A Filter Level Pruning Method for Deep Neural Network Compreesion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Snapshot-Distillation-Teacher-Student-Optimization-in-One-Generation"><span class="nav-number">16.</span> <span class="nav-text">Snapshot Distillation: Teacher-Student Optimization in One Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SeerNet-Predicting-Convolutional-Neural-Network-Feature-Map-Sparsity-through-Low-Bit-Quantization"><span class="nav-number">17.</span> <span class="nav-text">SeerNet: Predicting Convolutional Neural  Network Feature-Map Sparsity through Low-Bit Quantization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GOOGLE-Federated-Learning-Papers"><span class="nav-number">18.</span> <span class="nav-text">GOOGLE Federated Learning Papers:</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Applied-Federated-learning-Improving-Google-Keyborad-Query-Suggestions"><span class="nav-number">18.0.1.</span> <span class="nav-text">Applied Federated learning: Improving Google Keyborad Query Suggestions</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Federated-Learning-For-Mobile-Keyboard-Prediction"><span class="nav-number">18.0.2.</span> <span class="nav-text">Federated Learning For Mobile Keyboard Prediction</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Federated-Learning-Of-Out-Of-Vocabulary-Words"><span class="nav-number">18.0.3.</span> <span class="nav-text">Federated Learning Of Out-Of-Vocabulary Words</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Towards-Federated-Learning-At-Scale-System-Design"><span class="nav-number">18.0.4.</span> <span class="nav-text">Towards Federated Learning At Scale: System Design</span></a></li></ol></li></ol><li class="nav-item nav-level-3"><a class="nav-link" href="#In-situ-AI-Towards-Autonomous-and-Incremental-Deep-Learning-for-IoT-Systems"><span class="nav-number">19.</span> <span class="nav-text">In-situ AI : Towards Autonomous and Incremental Deep Learning for IoT Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#新的思考part"><span class="nav-number">20.</span> <span class="nav-text">新的思考part</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Task-Adaptive-Incremental-Learning-for-Intelligent-Edge-Devices"><span class="nav-number">21.</span> <span class="nav-text">Task-Adaptive Incremental Learning for Intelligent Edge Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distilling-Critical-Paths-in-Convolutional-Neural-Networks"><span class="nav-number">22.</span> <span class="nav-text">Distilling Critical Paths in Convolutional Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Orchestrating-Development-Lifecycle-of-Machine-Learning-Based-IoT-Applications-A-Survey"><span class="nav-number">23.</span> <span class="nav-text">Orchestrating Development Lifecycle of Machine Learning Based IoT Applications: A Survey</span></a></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yunyan.hong</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '214b2aee446518ccee23',
          clientSecret: '6b5e9007abf73fbcdce7d46cc4ae66a5fa5e6a3d',
          repo: 'hongyunyan.github.io',
          owner: 'hongyunyan',
          admin: ['hongyunyan'],
          id: location.pathname,
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>



  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
