<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="这是一个edge computing的research学习blog。 Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge ASPLOS 2017 University of Michigan  这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把">
<meta property="og:type" content="article">
<meta property="og:title" content="Edge Computing 论文阅读">
<meta property="og:url" content="http://yoursite.com/2019/10/06/edge-computing/index.html">
<meta property="og:site_name" content="Yunyan Hong">
<meta property="og:description" content="这是一个edge computing的research学习blog。 Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge ASPLOS 2017 University of Michigan  这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/1.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/2.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/3.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/5.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/4.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/6.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/7.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/9.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/8.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/10.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/11.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/12.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/13.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/14.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/15.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/16.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/17.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/18.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/19.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/20.png">
<meta property="og:image" content="http://yoursite.com/2019/10/06/edge-computing/21.png">
<meta property="og:updated_time" content="2019-12-07T08:57:21.951Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Edge Computing 论文阅读">
<meta name="twitter:description" content="这是一个edge computing的research学习blog。 Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge ASPLOS 2017 University of Michigan  这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把">
<meta name="twitter:image" content="http://yoursite.com/2019/10/06/edge-computing/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/10/06/edge-computing/">





  <title>Edge Computing 论文阅读 | Yunyan Hong</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yunyan Hong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/06/edge-computing/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="yunyan.hong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yunyan Hong">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Edge Computing 论文阅读</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-06T14:10:27+08:00">
                2019-10-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Research/" itemprop="url" rel="index">
                    <span itemprop="name">Research</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这是一个edge computing的research学习blog。</p>
<h3 id="Neurosurgeon-Collaborative-Intelligence-Between-the-Cloud-and-Mobile-Edge"><a href="#Neurosurgeon-Collaborative-Intelligence-Between-the-Cloud-and-Mobile-Edge" class="headerlink" title="Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge"></a>Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge</h3><ul>
<li>ASPLOS 2017</li>
<li>University of Michigan</li>
</ul>
<p>这篇文章主要讲的是说，如何让端设备来分担一些云设备的计算量。在我们传统的语音助手等设备中，我们传统的做法是把所有数据传到云上去，然后让云做完计算，然后再传回设备。但是当我们传输的不是文本数据，而有视频数据、图片数据、语音数据等的时候，我们会发现这些数据量是非常大的，会带来传输压力，计算压力，能耗问题，云端吞吐等一系列问题。因此就希望能将部分计算推到边缘设备上。</p>
<p>文章的主要关注的是对DNN模型的端云协同计算，设计了Neurosurgeon，是一种轻量级调度程序，对DNN自动划分哪些层在端设备上做，哪些层在云上做。</p>
<p>作者先测试了一下目前仅在云上训练的情况，用AlexNet作为我们的试验DNN结构，然后用一张152kb的image来做inference，来测试了communication latency，computation latency， end-to-end latency和energy consumption。得到了下面的几点发现：</p>
<ul>
<li>数据传输延迟通常高于移动计算延迟，尤其是在3G和LTE上。</li>
<li>与移动处理相比，云处理具有显着的计算优势，但由于数据传输开销太大，从end-to-end的角度来说它并不是总是保持优势的。</li>
<li>与仅使用云的方法相比，本地移动执行通常会导致更低的延迟和能耗，而如果使用快速Wi-Fi连接，则仅云方法可实现更好的性能。</li>
</ul>
<p>然后作者分析了DNN中的每个层在数据量和计算的特性。包括了fully-connected layer, convolution&amp;local layer, pooling layer, activation layer, normalization layer, softmax layer, argmax layer, dropout layer等。</p>
<ul>
<li>conv和fc层占据了主要的计算时间，尤其是fc层， 移动GPU上的卷积和池化层的延迟相对较小，而完全连接的层导致高延迟。</li>
<li>前几个conv的数据量很大，后面的逐渐减少。</li>
<li>卷积和池化层主要位于网络的前端，而完全连接的层位于后端。</li>
<li>卷积层（convolution layer) 增加数据，然后池化层(pooling)减少数据，数据的大小是不断的在减少的。</li>
<li>数据大小从前到后不断减少，而从前往后看每层在设备上的计算延迟通常更高，这表明在设备和云之间的DNN中间的计算分区的独特机会。</li>
</ul>
<p>然后作者实验了在alexnet的每个层作为分层进行测试latency和energy，在alexnet使用GPU和WIFI的情况下，最佳的切分点在DNN的中间层。</p>
<p>然后作者把上面的发现，扩展到其他DNN上进行实验。发现划分DNN的最佳方法取决于网络的拓扑结构和组成层。 在CV领域，DNN的最佳分区点在网络中间，而对于ASR和NLPDNN网络，在开头或结尾划分则更有利。因此对于不同的网络而言，划分点都是不同的，因此我们需要一个能对不同网络自动化分切分点的机制。</p>
<p><img src="/2019/10/06/edge-computing/1.png" width="100%"></p>
<p>于是论文就提出了Neurosurgen这个系统，整个工作的流程是这样的：</p>
<ol>
<li>系统先分析提取DNN的架构，每层的类型和配置</li>
<li>然后系统用一个预测模型，来估计每层在云端和设备端的latency和energy consumption</li>
<li>根据上面预测的结果，结合网络带宽和云端负载情况，系统挑选出最合适的切分点。</li>
<li>然后就根据划分点，然后在划分点前由端设备计算，然后将最后一层的输出发送到云端，由云端完成后续的计算，再把结果发回给设备端。</li>
</ol>
<p>这边提到的预测模型，是根据已知的层参数和对应的latency，energy消耗来拟合作的一个对数回归函数。</p>
<p>最后，作者使用8个不同的DNN作为我们的基准，通过Wi-Fi，LTE和3G无线连接，仅支持CPU和GPU的端平台，来评估Neurosurgeon。进行了latency，energy，和MAUI架构的对比，对网络情况的适应性测试，对Server load变化适应性测试，和数据中心吞吐量的指标测评。</p>
<p>与仅云处理相比，神经外科医生在8个基准测试中实现了平均3.1倍和最高达40.7倍的连续加速，平均降低了59.5％和最高达94.7％的移动能耗，并提高了数据中心的吞吐量平均1.5倍，最高为6.7倍。</p>
<blockquote>
<p>吃饭的时候聊到说目前的网络大部分层的output的data size都是大于原有input的，所以其实如果要找到一层size比较小的情况然后发到云上，那一般在很后面的层了，不过好像后面的fc层的确是latency比较大的层，可能也是合理的吧。cq学长提到说，对这样的一部分在设备端，一部分在云上的，是不是应该考虑自己建一个网络，而不是用现有的网络进行分割。</p>
</blockquote>
<p><br></p>
<h3 id="Distributed-Deep-Neural-Networks-over-the-Cloud-the-Edge-and-End-Devices"><a href="#Distributed-Deep-Neural-Networks-over-the-Cloud-the-Edge-and-End-Devices" class="headerlink" title="Distributed Deep Neural Networks over the Cloud, the Edge and End Devices"></a>Distributed Deep Neural Networks over the Cloud, the Edge and End Devices</h3><ul>
<li>ICDCS 2017 (B)</li>
<li>Harvard University</li>
</ul>
<p>本文主要关注的也是end devices, edge和cloud协同进行对网络进行inference。主要的方法也是先在end devices算，然后end结束以后判断一下end算的符不符合confident，符合就直接作为结果返回，如果不足够，就把当前的结果作为输入输给edge，继续算剩下的layers，然后edge结束再进行新一轮判断，符合就作为结果返回，如果不够就再输给cloud算。【我的理解是整个end，edge，cloud的所有层拼起来是一个完整的DNN，仿佛是这个意思哈，整个是看能不能提前exit的意思，到时候看一下他引用的BranchyNet怎么做early exit的】。</p>
<p><img src="/2019/10/06/edge-computing/2.png" width="100%"></p>
<p>因为你的end device，或者是edge都可以是多个组成的，所以当他们各自算完以后，有一个aggregation的步骤，这边给出了三种方法，Max pooling，Average Pooling和Concatenation。</p>
<p>这边DDNN的training part我感觉我没有理解的很清楚，反正他说是根据BranchyNet的方法，所以到时候再说吧。这边有提到的是说</p>
<blockquote>
<p>to train the DDNN we form a joint optimization problem as minimizing a weighted sum of the loss functions of each exit.</p>
</blockquote>
<p>然后对于inference的exit的threshold，这边用的是求一个normalized entropy[虽然为什么用熵我也不是很了解2333]</p>
<p><img src="/2019/10/06/edge-computing/3.png" width="50%"></p>
<p>这边的测试选用的是6个end device，一个edge和一个cloud, 那六个device可以理解为一个交通口不同位置的摄像头，在抓拍照片，然后我们就是要识别这些抓拍到的照片里面的对象。发现多个device的时候，我们其实是相比单个device提高了精准度的，当device少的时候，更多的sample最后被扔到云上去后续计算了，而device增多的时候，在device本身能解决的sample也增多了。最后的threshold设为了0.8，这样达到最后overall 97的准确率，并有62%的sample没有被发到云上。</p>
<p>最后的结果反正就是说这样的做法准确率也很高，容错性也很好，也减少了传输的cost。 </p>
<p><br></p>
<h3 id="Big-Little-Deep-Neural-Network-for-Ultra-Low-Power-Inference"><a href="#Big-Little-Deep-Neural-Network-for-Ultra-Low-Power-Inference" class="headerlink" title="Big/Little Deep Neural Network for Ultra Low Power Inference"></a>Big/Little Deep Neural Network for Ultra Low Power Inference</h3><ul>
<li>CODES 2015（B）</li>
<li>Seoul National University + Samsumg</li>
</ul>
<p>这篇文章就是非常典型的大小网络，他认为说以图片分类为例，大部分的sample其实都用不到那么复杂的网络，只要一个简单的小一点的网络其实就能实现比较好的结果了，并且这些小的网络可以很大程度的节省energy。所以他就是提出说要先让sample跑小网络，然后跑完检测说这个结果靠谱么，如果靠谱就直接作为最终的结果，如果不靠谱就再扔到大网络里面去跑。</p>
<p><img src="/2019/10/06/edge-computing/5.png" width="80%"></p>
<p>对于这个区分靠谱不靠谱，这边给出的想法是用一个score margin来作为指标。score margin这边给的是1st score - 2st score. 感觉作为一个分类问题，这样的设计方法还是蛮合理当然也很直观233.【感觉大小网络的一个研究点不就在于怎么判断我小网络的结果是可以的，不需要大网络来算了么】然后对于这个score margin，我们再设定一个阈值，如果大于阈值，我就认为我相信这个结果，如果小于，那就扔到大网络里面去。</p>
<p>然后对于这个挑阈值的问题，这边给出了两个方法，一个是固定的threshold，一个是dynamic调整threshold。</p>
<ul>
<li><p>static Threshold的想法是说，我一个比较好的threshold是一方面可以尽可能少的用到大网络，另一个是我要减少loss of inference accuracy。所以就在这两个方向做tradeoff，来获得一个合适的threshold值</p>
</li>
<li><p>dynamic threshold的想法是说，首先我将整个问题转化为最大化下面这个式子，这边原来想最大化的是P(correct)，但是我们认为这个其实可以认为是下面这个和网络算出来的score margin线性相关的，所以就用下一个式子来表示【因为P也不好算嘛】【当然其实这个要是等价，首先的前提就是说score margin决定结果是不是对的这个想法是可信的，这个part我具体没有了解过，是不是这样靠谱的。】然后那我要最大化下面这个式子，我怎么来找到合适的threshold的呢？这边作者给出的方法比较直接，我先初始化$Theta$和$\Delta$,然后每次我们比较threshold取$Theta$和$Theta + Delta$的下面这个式子的结果大小，如果$Theta$比较好，那就继续用这个，然后调整$Delta$,如果是后者比较好，就调整为后者，然后也调节一下$Delta$，整个过程就是一个梯度感觉。</p>
<p><img src="/2019/10/06/edge-computing/4.png" width="70%"></p>
</li>
</ul>
<p>然后这边实验部分还提到了一个对应做了一个hardware accelerator来处理，这个part没有太了解懂，也不是很重要吧，先放一放。然后作者在MNIST和ImageNet两个数据集上做了测试，来验证自己的想法是work的，还比较了不同小网络的结果。另外还比较了SRAM size的大小对energy的影响，在一定程度下，SRAM增大，energy consumption就会降低，因为SRAM增大，减少了off-chip DRAM access.</p>
<p><br></p>
<h3 id="The-Cascading-Neural-Network-Building-the-Internet-of-Smart-Things"><a href="#The-Cascading-Neural-Network-Building-the-Internet-of-Smart-Things" class="headerlink" title="The Cascading Neural Network: Building the Internet of Smart Things"></a>The Cascading Neural Network: Building the Internet of Smart Things</h3><ul>
<li>KNOWLEDGE AND INFORMATION SYSTEMS(B 会) 2017</li>
</ul>
<p>这篇文章感觉创新点没啥，主要的想法就是在一个网络里面，可以每层都直接接一个softmax，然后来判断是不是已经够了，不用继续往后面训练了。反正就是一个网络里面切出多个part，每个part结束都连一个softmax，然后判断现在的结果达标了么，没达标继续，达标了就结束。判断好没好，是选了softmax结果里面的max值是不是大于了阈值。这边说的网络的训练，可以直接先以传统的方式训练本身的网络，然后再保留每个层的中间结果，去训每层外接的softmax的参数就可以了。</p>
<p><br></p>
<h3 id="Edge-Intelligence-Paving-the-Last-Mile-of-Artificial-Intelligence-with-Edge-Computing"><a href="#Edge-Intelligence-Paving-the-Last-Mile-of-Artificial-Intelligence-with-Edge-Computing" class="headerlink" title="Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing"></a>Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing</h3><p>一篇edge intelligence的综述文章，中文翻译链接<a href="http://tongtianta.site/paper/46983" target="_blank" rel="noopener">http://tongtianta.site/paper/46983</a></p>
<p><br></p>
<h3 id="BranchyNet-Fast-Inference-via-Early-Exiting-from-Deep-Neural-Networks"><a href="#BranchyNet-Fast-Inference-via-Early-Exiting-from-Deep-Neural-Networks" class="headerlink" title="BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks"></a>BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks</h3><ul>
<li>2017</li>
<li>Harvard U</li>
</ul>
<p>一篇exit early的很有名的paper, 在网络里面插多个exit点。这篇文章讲了他怎么train 整个带exit的网络，首先用原始的网络训练完的参数初始化这个带exit的网络，然后再train这个新的网络，loss是带权重的每个exit处的loss function的累加和，带权重是指前面的exit branch的权重高，后面的exit branch的权重低。</p>
<p>这篇文章网络的结果是不仅时间短了，而且我看数据，三个网络里面的两个网络的acc也是比原有网络提升了0.几个点的。感觉很有意思。</p>
<p>文章里面提到的几个观点和解释也很有意思：</p>
<ul>
<li>因为有部分sample在inference时候是在提前退出的，所以说做bp的时候layer层比较少，这样就更可以抓到discriminative的features【感觉这就很神奇啊，也就是说层数少的网络可以抓住更重要的feature，但是层数多的网络可能能更全面的进行计算？】</li>
<li>exit point就像提供了一种正则化，来避免很多sample被overfit，所以提高了acc。</li>
</ul>
<p><br></p>
<blockquote>
<p>论文读到现在的感受：</p>
<ul>
<li>首先大家的目标其实是找到一个网络可以算的更快【所以说直接目标不是要他多小，主要想的是让他算的快】</li>
<li>然后大家很大部分的方法是，当我觉得我目前几层算的够了，我就提前退出。然后这个怎么提前退出，有的人一个网络设一个early exit点，有的设好几个，有的是只在conv层后面设。一般都是加个softmax层，这样根据他softmax的结果来算他的sc，根据threshold来判断能否退出。</li>
<li>感觉大家做的很没有创意啊…所有的论文感觉都是同一个思想，除了exit点设计的不一样，都没有更改判断是否exit的方式。</li>
<li>说到大小网络的话，其实做的人很少，大小网络的话，就是一个小网络算完判断是否ok，不ok继续大网络计算，然后他的ok不ok还是sc来判断。然后应用的话一般都是小网络放device上，大网络放云端吧。</li>
<li>不过这边的提出其实也不是专门针对edge的问题的。</li>
<li>大家说的都是inference的时候用这些，没有边训练边调整模型的。好像目前就没有说如何在设备端做training的。</li>
<li>奥目前的压缩网络好像就不能真实实际的减少计算时间，因为没有对应的算子保证？，那些置0的weight还是会被计算到，所以现在的压缩还是在模拟层面的？</li>
<li>感觉那个判断是否confident的不就是那个approximate网络里面的predictor么？为什么都不用网络做，是因为目的是减少计算时间，所以用一个网络过于慢了吗？</li>
<li>感觉应该看一下那个online learning那种的思想么？学习边做边调整 ?</li>
<li>还有的就是用近似网络来近似复杂的算法，用一个predictor来判断这个数据能不能近似，然后再来用近似网络进行近似。</li>
<li>感觉就两种方法– 一种就是先根据input来判断能不能用小网络来替换大网络，另一种就是说根据小网络结果来判断是不是需要大网络重新算。</li>
<li>我们现在要想的是考虑云端和设备端的协同，我们有哪些可以做的事情，而不是单单考虑说如何在设备端加速神经网络速度，来适配设备端的需求。感觉眼界可以再放大一点。目前有的<ul>
<li>神经网络加速</li>
<li>神经网络根据数据分布调整，就可以选取全模型中 对当前数据分布比较重要的point来调整小网络。</li>
</ul>
</li>
</ul>
</blockquote>
<p><br></p>
<h3 id="distilling-the-Knowledge-in-a-Neural-Network"><a href="#distilling-the-Knowledge-in-a-Neural-Network" class="headerlink" title="distilling the Knowledge in a Neural Network"></a>distilling the Knowledge in a Neural Network</h3><ul>
<li>2015</li>
<li>Hinton, Google</li>
</ul>
<blockquote>
<p>因为这篇文章实在是太火了，所以这边会摘取各位朋友对这篇文章的理解和分析。</p>
</blockquote>
<p>知识蒸馏的motivation：</p>
<blockquote>
<p>Knowledge Distill是一种简单弥补分类问题监督信号不足的办法。传统的分类问题，模型的目标是将输入的特征映射到输出空间的一个点上，例如在著名的Imagenet比赛中，就是要将所有可能的输入图片映射到输出空间的1000个点上。这么做的话这1000个点中的每一个点是一个one hot编码的类别信息。这样一个label能提供的监督信息只有log(class)这么多bit。然而在KD中，我们可以使用teacher model对于每个样本输出一个连续的label分布，这样可以利用的监督信息就远比one hot的多了。另外一个角度的理解，大家可以想象如果只有label这样的一个目标的话，那么这个模型的目标就是把训练样本中每一类的样本强制映射到同一个点上，这样其实对于训练很有帮助的类内variance和类间distance就损失掉了。然而使用teacher model的输出可以恢复出这方面的信息。具体的举例就像是paper中讲的， 猫和狗的距离比猫和桌子要近，同时如果一个动物确实长得像猫又像狗，那么它是可以给两类都提供监督。综上所述，KD的核心思想在于”打散”原来压缩到了一个点的监督信息，让student模型的输出尽量match teacher模型的输出分布。其实要达到这个目标其实不一定使用teacher model，在数据标注或者采集的时候本身保留的不确定信息也可以帮助模型的训练。</p>
</blockquote>
<p>文章的蒸馏方法主要是依靠soften了softmax的prob来实现的。以MINST为例，比如teacher net识别这个图片是2的概率为0.99，为3的概率为0.01，为7的概率为0.0001。那我的student的网络如何能学到除了这张图应该识别为2的知识呢？也就是要学到自己在对这张图片做softmax的时候，为3的概率应该也是比7大的。所以这边就提出了soften（也就是升温）</p>
<p>传统的softmax函数为$q_i = \frac{exp(zi)}{\sum_j exp(z_i) }$，我这边通过升温以后使他变为$q_i = \frac{exp(zi / T)}{\sum_j exp(z_i/T) }$。也就是说原来除以1，现在除以一个比1大的数，这样让每个softmax的值之间差距缩小。然后我们用这个soften的softmax prob作为student学习的一个soft target，传统的label产生的交叉熵作为hard target ，soft target和hard target一起指导student net学习。</p>
<p>实验部分，作者使用了MNIST进行图片分类的实验，一个有趣的地方在于（和论文前半部分举的2和3识别的例子呼应），作者在数据集中有意地去除了标签为3的样本。没有KD的student网络不能识别测试时候提供的3的数字，有KD的student网络能够识别一些3（虽然它从来没有在训练样本中出现过！）。后面，作者在语音识别和一个Google内部的很大的图像分类数据集（JFT dataset）上做了实验。</p>
<p>论文的另一个部分是集成模型，训练大数据集的一个简单方法是集成模型（将数据分成数个子集，分别训练然后集成），这种方法很容易并行化，但是却在测试的时候需要耗费大量的计算资源，而distillation可以解决这个问题。集成的一个主要问题是容易过拟合，这里也是利用soft targets的思想来处理这个问题，通过KL散度约束新模型与全体及分别的概率分布比较相似。</p>
<p>soft target还能用于避免overfit，避免模型的过度训练。</p>
<blockquote>
<p>突然觉得这个集成模型，不是很像我们实际应该分散在每个edge上的设备么?云端应该是那个general的net，然后edge是那个special的net。</p>
</blockquote>
<p><br></p>
<p>两篇近似网络的前文:</p>
<h3 id="Neural-Acceleration-for-General-Purpose-Approximate-Programs-2012"><a href="#Neural-Acceleration-for-General-Purpose-Approximate-Programs-2012" class="headerlink" title="Neural Acceleration for General-Purpose Approximate Programs(2012)"></a>Neural Acceleration for General-Purpose Approximate Programs(2012)</h3><h3 id="Prediction-Based-Quality-Control-for-Approximate-Accelerators-2015"><a href="#Prediction-Based-Quality-Control-for-Approximate-Accelerators-2015" class="headerlink" title="Prediction-Based Quality Control for Approximate Accelerators(2015)"></a>Prediction-Based Quality Control for Approximate Accelerators(2015)</h3><p>第一篇文章提出了我们能用神经网络来近似诸多函数。我们应当先选择合适的code部分来近似，要求这些code有固定size的input和固定size的output，这样才能保证我近似的神经网络输入输出的size是固定的。然后对于选择网络来拟合，这边首先是限定了能选择的网络拓扑结构的选择范围（比如隐层有1-2层，节点数最多是多少个），然后在训练各个拓扑下的网络，最后选择一个最好的网络，作为我们的近似网络。</p>
<p>第二篇文章提出了说我们不应该只有一个近似网络，我们还需要一个predictor来判断当前的输入适不适合用我们的近似网络进行近似，如果适合近似，我们才用我们的近似网络来计算，如果不适合，我们就用原来的code来计算。这边提出的predictor有两种类型，一种是table-based，另一种是network的。这边就是根据我能接受的最大的error diff来训练我的predictor。我觉得这边比较好的检验方法应该是比较每个获得的predictor的判断正确程度？论文里没有提到如何比较。</p>
<p><br></p>
<h3 id="Born-Again-Neural-Networks"><a href="#Born-Again-Neural-Networks" class="headerlink" title="Born-Again Neural Networks"></a>Born-Again Neural Networks</h3><ul>
<li>2018 ICML</li>
<li>南加州</li>
</ul>
<p>这篇文章的主要思想是下图的结构。也就是我先有一个teacher网络，然后用teacher网络去初始化第一个student网络，然后学生网络以预测正确标签，与教师输出分布相匹配这两个目标来进行训练。然后第一个student网络收敛后，就用它的参数去初始化下一个student网络，这样依次训练。最后把所有的student network集合起来作为我们的ensemble network，发现他的效果好于teacher网络。【但是这样多个net不是很占内存啥的么？速度也不快？所以是不是和原有的目标有违背?】奥好像是说他测试的时候会选这一群训出来的最后一个network来作为我们的BAN网络，和teacher网络进行比较。</p>
<p>另外他还提到可以用不同的拓扑结构的teacher网络辅导别的架构的student网络进行学习提升。</p>
<p><img src="/2019/10/06/edge-computing/6.png" width="100%"></p>
<p><br></p>
<h3 id="Rocket-Launching-A-Universal-and-Efficient-Framework-for-Training-Well-performing-Light-Net"><a href="#Rocket-Launching-A-Universal-and-Efficient-Framework-for-Training-Well-performing-Light-Net" class="headerlink" title="Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net"></a>Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net</h3><ul>
<li><p>2018 AAAI</p>
</li>
<li><p>清华 + 阿里</p>
<p>文章提出了一个新的方法来得到轻量的网络。下图是网络的结构，大小网络share了前n层网络的参数，并且他们是一起training的，因为作者认为小网络不仅仅要学习最后的结果，还要学习大网络学习的过程。对于整个网络的loss则为两个网络各自的cross-entropy以及l(x)和z(x)之间hint函数的。</p>
<p><img src="/2019/10/06/edge-computing/7.png" width="50%"></p>
<p>网络中l(x)和z(x)之间hint函数，作者给出了几种函数。（有些是q(x)和p(x)，就是softmax前或者softmax后）</p>
<p><img src="/2019/10/06/edge-computing/9.png" width="60%"></p>
<p>另外考虑到如果上面提到的网络的三个loss对两个网络一起调整参数，会导致大网络被小网络的质量影响，因此网络的bp中，对应的loss情况如下。也就是大网络只受自己的cross-entropy影响，另两个函数都用于调整小网络。</p>
<p><img src="/2019/10/06/edge-computing/8.png" width="50%"></p>
<p>作者最后发现，这样可以加快训练速度，并且让light net有更好的表现。</p>
</li>
</ul>
<p><br></p>
<h3 id="Collaborative-Learning-between-Cloud-and-End-Devices-An-Empirical-Study-on-Location-Prediction"><a href="#Collaborative-Learning-between-Cloud-and-End-Devices-An-Empirical-Study-on-Location-Prediction" class="headerlink" title="Collaborative Learning between Cloud and End Devices: An Empirical Study on Location Prediction"></a>Collaborative Learning between Cloud and End Devices: An Empirical Study on Location Prediction</h3><ul>
<li>SEC 2019</li>
<li>MSRA + 清华</li>
</ul>
<p>这篇文章讲的是，在以前的方法里面都是云端给device端提供一个小网络，供其使用，就结束了，小网络没有根据自己的数据进行新的迭代，这样对于device中不同的数据分布，原有的固定的小网络没有办法达到一个非常好的结果水平。</p>
<p>因此这边就提出说能不能让我们在device端不断inference的时候，并且用这些数据来调整自己device上的网络呢。所以这边就提出说我希望通过协同学习的方法来不断的提升network的效果。</p>
<p><img src="/2019/10/06/edge-computing/10.png" width="100%"></p>
<p>上图显示了这个协同学习的过程图。</p>
<ol>
<li>首先云端根据原有的数据训练了第一个model。</li>
<li>当一个device新加入这个系统后，云端会把最新的的云端模型压缩成一个小网络发给device。然后在接下来的一个时间段里面device就用这个小网络进行inference。</li>
<li>在过一段时间以后，device端会根据云端最新的网络，根据KD的思想，更新自己的网络。</li>
<li>然后根据device们最新的network，来指导云端的网络进行KD的学习，获得新的网络数据。</li>
<li>3和4不断的迭代发生，不停地对网络进行训练和提升。</li>
</ol>
<p>当device数量很多的时候，云端单独一个的network没有办法满足所有device的需求，所以就根据聚类，提供K个network提供给n个device，进行对应的KD调整。这边所有的KD的loss函数都是比较基础的函数，soft target + hard target一起进行指导。</p>
<p>【这边提到说device training是全部在device上完成的？所以就很好奇怎么搞的？？？】</p>
<p>这边竟然是用的RNNemmmm。</p>
<p><br></p>
<h3 id="MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications"><a href="#MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications" class="headerlink" title="MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"></a>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</h3><ul>
<li>2017 Google</li>
</ul>
<p>文章解析见<a href="https://www.jiqizhixin.com/graph/technologies/c0bc9a32-bd3d-4df2-b0de-c433419a19e6" target="_blank" rel="noopener">https://www.jiqizhixin.com/graph/technologies/c0bc9a32-bd3d-4df2-b0de-c433419a19e6</a></p>
<h3 id="ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices"><a href="#ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices" class="headerlink" title="ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"></a>ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</h3><ul>
<li>2017 Face++</li>
</ul>
<p>文章解析见<a href="https://zhuanlan.zhihu.com/p/32304419" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32304419</a></p>
<h3 id="ThiNet-A-Filter-Level-Pruning-Method-for-Deep-Neural-Network-Compreesion"><a href="#ThiNet-A-Filter-Level-Pruning-Method-for-Deep-Neural-Network-Compreesion" class="headerlink" title="ThiNet: A Filter Level Pruning Method for Deep Neural Network Compreesion"></a>ThiNet: A Filter Level Pruning Method for Deep Neural Network Compreesion</h3><ul>
<li>ICCV 2017</li>
</ul>
<p>文章解析见<a href="https://blog.csdn.net/wspba/article/details/77427960" target="_blank" rel="noopener">https://blog.csdn.net/wspba/article/details/77427960</a> 和 <a href="https://blog.csdn.net/u014380165/article/details/77763037" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/77763037</a></p>
<p><br></p>
<h3 id="Snapshot-Distillation-Teacher-Student-Optimization-in-One-Generation"><a href="#Snapshot-Distillation-Teacher-Student-Optimization-in-One-Generation" class="headerlink" title="Snapshot Distillation: Teacher-Student Optimization in One Generation"></a>Snapshot Distillation: Teacher-Student Optimization in One Generation</h3><ul>
<li>2019 CVPR</li>
<li>Johns Hopkins U</li>
</ul>
<p>这篇文章是一篇Teacher-Studenet模型的优化工作。这边提出的是觉得一方面目前在BAN提出后，这个多个studenet一个个训练下去，时间成本非常高，需要k×base model的时间。因此他就认为，我能不能每个老师不是我每个iteration结束时候的network，而是我们在每个epochs结束时候就选取当前的网络为新的teacher进行计算，来缩短时间。</p>
<p>这边要这样训练有三点需要满足：</p>
<ol>
<li>teacher 的network应该要有比较好的质量</li>
<li>teacher和student需要有差异。【所以这边采用的是每个min-batch里面用从大变小的learning rate来收敛。但teacher和student到底差不差一代，没看懂233，也非常好奇】</li>
<li>需要加强secondary信息的传递。【也就是一个dark knowledge的概念，我们不仅要学绝对的那个标准，还要学跟他相似的其他类信息，所以说他这边用loss函数抑制了前面的teacher的top1的百分比，让后续的学生更好的学习】</li>
</ol>
<p><br></p>
<h3 id="SeerNet-Predicting-Convolutional-Neural-Network-Feature-Map-Sparsity-through-Low-Bit-Quantization"><a href="#SeerNet-Predicting-Convolutional-Neural-Network-Feature-Map-Sparsity-through-Low-Bit-Quantization" class="headerlink" title="SeerNet: Predicting Convolutional Neural  Network Feature-Map Sparsity through Low-Bit Quantization"></a>SeerNet: Predicting Convolutional Neural  Network Feature-Map Sparsity through Low-Bit Quantization</h3><ul>
<li>cvpr 2019</li>
<li>MSRA</li>
</ul>
<p>文章主要的思想是说，我先用一个很小的bit量，比如1,2,4来计算我feature map和weight的结果，来判读我输出时候哪些值是有用的（因为relu和max-pooling会让大部分的计算都作废了），然后根据算出来真实会被选用的那些位置，去进行精确的计算，来节省计算量。【每一层都先预测，然后真实计算】</p>
<p>并且文章提出利用AVX加速，并且通过保存非0值的column和row坐标来表示feature map,来进行软硬层结合的加速。</p>
<p><br></p>
<h3 id="GOOGLE-Federated-Learning-Papers"><a href="#GOOGLE-Federated-Learning-Papers" class="headerlink" title="GOOGLE Federated Learning Papers:"></a>GOOGLE Federated Learning Papers:</h3><h5 id="Applied-Federated-learning-Improving-Google-Keyborad-Query-Suggestions"><a href="#Applied-Federated-learning-Improving-Google-Keyborad-Query-Suggestions" class="headerlink" title="Applied Federated learning: Improving Google Keyborad Query Suggestions"></a>Applied Federated learning: Improving Google Keyborad Query Suggestions</h5><h5 id="Federated-Learning-For-Mobile-Keyboard-Prediction"><a href="#Federated-Learning-For-Mobile-Keyboard-Prediction" class="headerlink" title="Federated Learning For Mobile Keyboard Prediction"></a>Federated Learning For Mobile Keyboard Prediction</h5><h5 id="Federated-Learning-Of-Out-Of-Vocabulary-Words"><a href="#Federated-Learning-Of-Out-Of-Vocabulary-Words" class="headerlink" title="Federated Learning Of Out-Of-Vocabulary Words"></a>Federated Learning Of Out-Of-Vocabulary Words</h5><h5 id="Towards-Federated-Learning-At-Scale-System-Design"><a href="#Towards-Federated-Learning-At-Scale-System-Design" class="headerlink" title="Towards Federated Learning At Scale: System Design"></a>Towards Federated Learning At Scale: System Design</h5><p>这几篇文章主要就是讲了目前google利用联邦学习做的一些应用提升的尝试，包括了keyword的query，prediction等。主要的方法都是说当设备符合充电且连wifi的前提条件，并且满足的数量达到我们的threshold后，从这些满足条件的设备中选取一些设备，发给我们云端目前的模型checkpoint，让他们用自己本地的数据训练这些模型，然后训练后把模型参数返回，然后云端federated Average处理后，生成新的云端模型，并把模型传到device上，作为他们的新model。目前对不同的设备的不同dataset量，用了加权的方法来平衡不同的贡献。</p>
<p>还有的一些问题包括了：</p>
<ul>
<li>convergence time </li>
<li>Bias</li>
<li>Bandwidth</li>
<li>Device Scheduling</li>
</ul>
<p><br></p>
<h3 id="In-situ-AI-Towards-Autonomous-and-Incremental-Deep-Learning-for-IoT-Systems"><a href="#In-situ-AI-Towards-Autonomous-and-Incremental-Deep-Learning-for-IoT-Systems" class="headerlink" title="In-situ AI : Towards Autonomous and Incremental Deep Learning for IoT Systems"></a>In-situ AI : Towards Autonomous and Incremental Deep Learning for IoT Systems</h3><ul>
<li>HPCA 2018</li>
<li>弗洛里达大学，litao老师组</li>
</ul>
<p>这篇文章主要画了个框架的饼，跟我们做的应该是非常相关的。</p>
<p>首先他提出了目前Iot面临的问题，比如实际使用中，噪音很重，很好的网络并不能很好的适应当前的状况；很多数据没有标注，也难以全部标注。然后我们要减少device到cloud的movement，然后又要低延时低energy损耗。然后他就提出了一个框架，实现automonous and incremental 学习。</p>
<p>这个框架的背景应用在要识别图像，异常检测、分类等。他提出的框架如下。</p>
<p><img src="/2019/10/06/edge-computing/11.png" width="80%"></p>
<p>首先他是说，我们先来做一个无监督的问题，把一张图片切成九块，然后打乱顺序，让网络来判断这九张图真实的相对顺序。然后他说这个网络是和我们上面提到的图片识别啊，异常检测，分类问题啊都非常相关的。并且前面基层的数据就是来抓取图片的特征的，我们可以通过这个无监督的网络前几层来帮助后面的那个inference网络提高acc，就类似一个pretrain的工作。</p>
<p>然后在上面那个无监督的网络（也叫diagnosis net)train的差不多了，就用少数有label的数据去train inference 的network，然后就得到一个inference net。然后我们把这两个都扔到device上去。然后对于实际拿到的图片，我们先通过diagnosis net，如果他识别顺序正确，我们就拿去做inference，如果不对，我就把他扔回去cloud，来调我的无监督模型，然后因为他们前面几层的参数是共享的，所以后面也会调整inference（猜测是用原有有label的数据继续辅助调整）。然后这样就是一个incremental的过程。</p>
<blockquote>
<p>这边这个无监督很好的解决了一个incremental的问题，可以参考应用一下，不然的确没法解决这个没有label的问题。然后这边的cloud和edge用的是同样的模型，不存在大小的问题。</p>
<p>当然学长说了这可能只是个饼，很难work。</p>
</blockquote>
<p><br></p>
<h3 id="新的思考part"><a href="#新的思考part" class="headerlink" title="新的思考part"></a>新的思考part</h3><p>端云协同需要决定的问题：</p>
<ol>
<li>你的端和云是要用一个网络么，还是大网络、小网络<ol>
<li>如果是大小网络，怎么指导学习呢，只能自己学习？</li>
<li>一个网络可以一起学习，可是那为啥还要你小网络的存在呢？</li>
</ol>
</li>
<li>你的端云的网络要不断的学习么，要incremental么<ol>
<li>如果要不断的学习，data没有标注怎么办<ol>
<li>无监督</li>
<li>大网络指导小网络</li>
</ol>
</li>
<li>如果不学习，那做啥优化呢？<ol>
<li>如果是大小网络，就是来判断我啥时候要用大网络？然后我咋调整小网络？</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><br></p>
<h3 id="Task-Adaptive-Incremental-Learning-for-Intelligent-Edge-Devices"><a href="#Task-Adaptive-Incremental-Learning-for-Intelligent-Edge-Devices" class="headerlink" title="Task-Adaptive Incremental Learning for Intelligent Edge Devices"></a>Task-Adaptive Incremental Learning for Intelligent Edge Devices</h3><ul>
<li>george mason U</li>
<li>最近新在arxiv上的一个2页的短文，感觉写的也很水，也没有说具体的技术细节，就画了个饼，可能到时候要扩展去投啥把，但是思想是和上次聊到的非常像。</li>
</ul>
<p>主要的思想就是说，我云端是各模型，然后我的device端是一个special的网络，针对各自的特点的网络。然后他认为special的网络是将云端的网络分成两个part以后组成的，就云端的网络前几层作为一个shared layers，每个special网络都共用这个shared layers，然后在后面几层可以decouple成多个critical path。然后device端只具有自己针对类别的critical path组成的网络，然后根据自己的数据微调。然后每个device把自己critical path调整的参数传给cloud，更改云端模型。</p>
<p><img src="/2019/10/06/edge-computing/12.png" width="80%"></p>
<p>他还能增加新的分类critical path，非常的迷惑了。</p>
<p>当然怎么分critical path不知道，怎么知道对应哪个device要用哪几个critical path，不知道，为什么能新增path，不知道。疯狂挠头？所以也不知道是个纯饼还是只是展示了部分工作。思路还是比较明显的，就是感觉这几个技术点还是不好解决的。</p>
<p><br></p>
<h3 id="Distilling-Critical-Paths-in-Convolutional-Neural-Networks"><a href="#Distilling-Critical-Paths-in-Convolutional-Neural-Networks" class="headerlink" title="Distilling Critical Paths in Convolutional Neural Networks"></a>Distilling Critical Paths in Convolutional Neural Networks</h3><ul>
<li>楼上文章的组，发在nips的workshop里面，是一篇短文，算是上面一篇文章的前序文章</li>
</ul>
<p>文章讲的就是如何找到CNN的critical path，来针对的distill。这边用的是mean absolute activation + contribution index + AM visualization三种思想。</p>
<p>在distill critical path中，他们首先选择前多少层是basic，不用挑选critical path的。然后计算每层的mean absolute activation、contribution index，把他们的结果相乘来选择filter。根据我们设定的reserved ratio来决定我们能选择多少个filters。另外因为抽取了filter，会改变最后logit层的情况，所以就是被删掉的其他class的logit对应会置为0。</p>
<p><br></p>
<h3 id="Orchestrating-Development-Lifecycle-of-Machine-Learning-Based-IoT-Applications-A-Survey"><a href="#Orchestrating-Development-Lifecycle-of-Machine-Learning-Based-IoT-Applications-A-Survey" class="headerlink" title="Orchestrating Development Lifecycle of Machine Learning Based IoT Applications: A Survey"></a>Orchestrating Development Lifecycle of Machine Learning Based IoT Applications: A Survey</h3><p>文章的整体架构如下图所示。<br>model Development 讲的是根据你IoT的需求找一个对应的model，并且根据设备的情况优化model，并选用对应的框架来把生成模型。</p>
<ol>
<li>模型本身分为三类，传统的机器学习方法，deep learning和reinforcement learning。一般就data量少的，追求轻量级的找TML，有比较多交互的用RL，别的用DL。 在DL中，AE可以用于异常检测或者预处理，GAN则可以用来增加一些samples。</li>
<li>在model generation部分，主要提及的是加速的问题，一般通过优化并行，data parallel或者model parallel来帮助加速。另外就是在Distributed的ML系统中，目前的update strategy用的倾向于异步的系统，且支持有掉队者，并且利用过时的思想来保证update的正确性。</li>
<li>在模型优化中，一方面是进行特征处理，在诸多数据中去除冗余数据，筛选重要的feature，来帮助优化模型。另外的是为了适配device的实际算力，一般会有几种处理方式，一种是针对这些小算力设备提出特殊的模型，比如MobileNet等，另一种是NAS，来搜索匹配合适的network，另一个则是模型压缩，包括剪枝、低秩分解，压缩的卷积filter，知识蒸馏等。</li>
<li>模型评估这边就比较基本了，就是用tp,fp,tn,fn,precison,recall,F1,mse,mae,mpe等这些指标来衡量模型。</li>
</ol>
<p>Model Deployment上，说实在的，不知道他在写啥，大概就是在将我把挑好的模型部署到实际的场景中，还会有对应哪些操作需要进行优化，来符合我的延迟、resource，storage，memory, output等情况。为了应对各种实际场景下的问题，提出了一些方法【总的来说不知道在说啥】</p>
<p>Model Audit就是在评估实际的应用中有没有有效安全可信的进行运作，安全方面介绍了一些攻击类型，提出应该构建怎么样的安全的平台或者框架，然后又提到关于fault tolerance的问题，要增强generalization的能力，包括正则化，增加data，提前退出等。以及在我们考虑一个模型的表现中，需要考虑model的precision，execution latency, bandwidth usage, resource Consumption和system throughput。</p>
<p>Model Acquisition部分就说了对数据的收集，数据的处理， 以及数据的融合处理。</p>
<p><img src="/2019/10/06/edge-computing/13.png" width="100%"></p>
<blockquote>
<p>【感觉不知道是自己没有抓住重点还是怎么回事，感觉这篇survey比较普通吧，更多的感觉侧重在了分布式的一些内容上?感觉对IoT方面的叙述没有那么全面把？其实主要是也不知道怎么判断一篇survey写的好不好23333</p>
</blockquote>
<p><br></p>
<h3 id="ReForm-Static-and-Dynamic-Resource-Aware-DNN-Reconfiguration-Framework-for-Mobile-Device"><a href="#ReForm-Static-and-Dynamic-Resource-Aware-DNN-Reconfiguration-Framework-for-Mobile-Device" class="headerlink" title="ReForm: Static and Dynamic Resource-Aware DNN Reconfiguration Framework for Mobile Device"></a>ReForm: Static and Dynamic Resource-Aware DNN Reconfiguration Framework for Mobile Device</h3><ul>
<li>DAC 2019</li>
<li>George Mason U</li>
</ul>
<p>感觉主要的思想就是在resource限制的情况下，静态/动态的删掉一些filter来满足需求。</p>
<p>在static分析中，总共抽出来三个resource相关限制：</p>
<ul>
<li>computation capacity constraint, 这个实际DNN使用情况用总共的乘法运算次数来表示</li>
<li>memory occupy constraint， 这个是包含了filter和每一层layer占的所有内存量</li>
<li>Energy consumption constraint, 包含了computation energy cost 和 memory access energy cost,前一个是跟乘法次数有关，后者跟memory情况有关。</li>
</ul>
<p>然后静态的调整就是在满足resource要求下，调整filter数目，来达到准确率高的情况。</p>
<p>动态则是对每个filter做的贡献排名，然后根据resource情况，逐渐删掉贡献少的filter，来达到比较合适的架构。</p>
<p><br></p>
<h3 id="MobiEye-An-Efficient-Cloud-based-Video-Detection-System-for-Real-time-Mobile-Applications"><a href="#MobiEye-An-Efficient-Cloud-based-Video-Detection-System-for-Real-time-Mobile-Applications" class="headerlink" title="MobiEye: An Efficient Cloud-based Video Detection System for Real-time Mobile Applications"></a>MobiEye: An Efficient Cloud-based Video Detection System for Real-time Mobile Applications</h3><ul>
<li>DAC 2019</li>
<li>Duke</li>
</ul>
<p>文章针对的是在设备上的对视频的实时detection，传统的都是仅仅在设备上收集数据，然后传给云端做分析的。作者提出：</p>
<ul>
<li>先用异步的deep feature flow来优化对视频的处理【就是关键帧用大网络分析，非关键帧用小网络，然后关键帧和非关键帧是异步进行处理的】</li>
<li>然后提出了Video-based Dynamic Scheduling(VDS) scheme，用这个来动态的判断当前的帧是不是关键帧，因为传统的选择关键帧就是说我定一个interval来选择，而不关心每一帧实际在干什么。主要的想法就是如果动画内容变化的快，则多选择关键帧，没啥变化就少选关键帧。</li>
<li>然后他提出了Spatial Sparsity Inference来稀疏结构，减少计算。他主要的稀疏想法就是把背景mask掉 ，或者根据brightness的差来mask无用的pixel。然后因为这是结构化的稀疏，所以能简化并加快了整个计算。G</li>
</ul>
<p><br></p>
<h3 id="An-Optimized-Design-Technique-of-Low-bit-Neural-Network-Training-for-Personalization-on-IoT-Devices"><a href="#An-Optimized-Design-Technique-of-Low-bit-Neural-Network-Training-for-Personalization-on-IoT-Devices" class="headerlink" title="An Optimized Design Technique of Low-bit Neural Network Training for Personalization on IoT Devices"></a>An Optimized Design Technique of Low-bit Neural Network Training for Personalization on IoT Devices</h3><ul>
<li>DAC 2019</li>
<li>Korea</li>
</ul>
<p>这篇文章的主要意思就是，根据普世数据train出来的模型用在真实场景中acc会掉很多，但是用少量真实场景数据在原本的模型训练完后再train一下，可以很大的提升acc。但是IoT的resource情况难以支持training，所以就提出通过利用low bit的方式（应该就是量化的思想）来在IoT上实现训练。通过low bit来减少对on-chip buffer的大量消耗，并且提出了一个freezing batch normalization的想法，来优化bn步骤的大量数据持有的计算（其实没有特别看明白量化的方法，大概就是一个2次幂的量化，把数据映射到对应的值上去做计算，然后BN的优化应该就是因为一个batch的数据on-chip没法算完，需要持有数据很久不断的算？然后他就一个个算，只用保存两个需要更新的参数就可以了，这样就减少了hold 的data量，更适合在IoT上training)</p>
<p>前面那个再用点真实数据train应该就是一个incremental learning的体现。</p>
<p><br></p>
<h3 id="Context-Aware-Convolutional-Neural-Network-Over-Distributed-System-in-Collaborative-Computing"><a href="#Context-Aware-Convolutional-Neural-Network-Over-Distributed-System-in-Collaborative-Computing" class="headerlink" title="Context-Aware Convolutional Neural Network Over Distributed System in Collaborative Computing"></a>Context-Aware Convolutional Neural Network Over Distributed System in Collaborative Computing</h3><ul>
<li>DAC 2019</li>
<li>Pennsylvania State University</li>
</ul>
<p>这边讲的就是一个多个视角的合作，整个思想就是说我多个视角的数据，我先根据视角内容来选择一些比较重要的view加权表示，来减少对所有视角的数据的需求，来达到一个比较节省数据传输和功耗的效果。整个过程如下图所示，用likelihood来表示每个part的重要性的感觉，然后再加权表示一个整个的view，来进行predictrion。</p>
<p><img src="/2019/10/06/edge-computing/14.png" width="100%"></p>
<p>文章的整体思路和18年CVPR的GVCNN有很相似的想法，都是改了原来MVCNN对所有view附以一致的权重的想法。但是GVCNN整体的网络还是非常的复杂(GVCNN就是view加权到group，再加权fusion以后输入网络判断】，不适合在device端应用。而这篇文章主要就是把这个用于distributed的网络上，前部分的device来用小网络判断一下自己的重要性，然后结合重要性传给cloud。</p>
<blockquote>
<p>我感觉这篇文章写的很不清楚…..整个感觉有点混乱，反正大致就是这么一个思想。G</p>
</blockquote>
<p><br></p>
<h3 id="Machine-Learning-at-Facebook-Understanding-Inference-at-the-Edge"><a href="#Machine-Learning-at-Facebook-Understanding-Inference-at-the-Edge" class="headerlink" title="Machine Learning at Facebook: Understanding Inference at the Edge"></a>Machine Learning at Facebook: Understanding Inference at the Edge</h3><ul>
<li>Facebook</li>
<li>HPCA 2018</li>
</ul>
<p>文章得出的结论有：</p>
<ul>
<li>安卓设备上，AI边缘计算硬件碎片化严重，也就是各种SoC非常的多，分布非常的广</li>
<li>移动端的CPU多样化，且非常的陈旧，72.1%的设备采用了6年前的CPU内核</li>
<li>移动端大部分的GPU性能并没有比CPU好多少，只有很少的GPU能达到CPU 2-3倍的性能。因此很多的mobile inference用于CPUs</li>
<li>DSP和NPU的情况也不容乐观，他们的可编程性也相对较差，OpenCL库目前还和很多设备不匹配，增加了困难性。</li>
<li><p>目前的潮流是软件层加速计算</p>
</li>
<li><p>首先关注的是可用性，然后再是加速问题</p>
</li>
<li>模型的准确性排在了模型的size之后考虑</li>
<li>模型性能在真实场景中的真实表现情况，是一个非常重要的问题</li>
</ul>
<p><br></p>
<h3 id="CAPTOR-A-Class-Adaptive-Filter-Pruning-Framework-for-Convolutional-Neural-Networks-in-Mobile-Applications"><a href="#CAPTOR-A-Class-Adaptive-Filter-Pruning-Framework-for-Convolutional-Neural-Networks-in-Mobile-Applications" class="headerlink" title="CAPTOR: A Class Adaptive Filter Pruning Framework for Convolutional Neural Networks in Mobile Applications"></a>CAPTOR: A Class Adaptive Filter Pruning Framework for Convolutional Neural Networks in Mobile Applications</h3><ul>
<li>ASPDAC 2019</li>
<li>George Mason U</li>
</ul>
<p>大概的思想就是先用AM来分析哪些filter对哪些class的分类比较有用，然后聚类，把结果放在表里面，真实使用的时候，根据对应真实场景的class类型，删除没有什么用的类的filter。</p>
<p><br></p>
<h3 id="ApDeepSense-Deep-Learning-Uncertainty-Estimation-Without-the-Pain-for-IoT-Application"><a href="#ApDeepSense-Deep-Learning-Uncertainty-Estimation-Without-the-Pain-for-IoT-Application" class="headerlink" title="ApDeepSense: Deep Learning Uncertainty Estimation Without the Pain for IoT Application"></a>ApDeepSense: Deep Learning Uncertainty Estimation Without the Pain for IoT Application</h3><ul>
<li>ICDCS 2018</li>
<li>UIUC, Amazon</li>
</ul>
<p>文章主要讲的是我用高斯分布来拟合我带有dropout的neural network，来达到一个近似计算的效果。从理论推导上发现每层的参数都是符合一个高斯分布的，所以他也就利用高斯分布来生成对应的参数，然后最后一层activation层，再根据他的特点，提出对应的分布，来进行计算。这样就代替了复杂的运算，然后得到一个比较近似且计算量小的方法。</p>
<p><br></p>
<h3 id="OpenEI-An-Open-Framework-for-Edge-Intelligence"><a href="#OpenEI-An-Open-Framework-for-Edge-Intelligence" class="headerlink" title="OpenEI: An Open Framework for Edge Intelligence"></a>OpenEI: An Open Framework for Edge Intelligence</h3><ul>
<li>ICDCS 2019</li>
<li>Wayne State U + 中科大</li>
</ul>
<p>文章提出了一个用在edge上的框架，可以部署在edge端的一个比较轻量的platform来进行一些数据处理计算和分享的框架。</p>
<p>整个结构大致为：</p>
<p><img src="/2019/10/06/edge-computing/15.png" width="80%"></p>
<p>其中：</p>
<ul>
<li>package manager: 可以理解为是一个类似Tensorflow Lite的东西，就是一个基本的框架module，然后他支持low power consumption和low memory footprint。这个框架来支持在edge端的training和inference，并且他具有一个real time的machine learning module，当需要这个module的时候，他会被设置最高优先级，然后满足他的各类资源需求。</li>
<li>Model Selector: 就是用来挑选针对当前case最为合适的model，他不仅包含了挑选模型本身，还有挑选对应的package，以及对应的edge hardware platforms。</li>
<li>libei就是一个API使得edge和cloud可以communicate和work together。</li>
</ul>
<p>当然目前这个还有一些待探究的open problems，包括了：</p>
<ol>
<li><p>EI algorithm 层面：</p>
<ul>
<li>how to reduce the model size while guaranteeing high accuracy.</li>
<li>collaboration between edges calls for an algorithm that runs in a distributed manner on multiple edges.</li>
<li>how to split an algorithm based on the computing resources of the edges.</li>
<li>how to achieve collaborative learning on the cloud and edges is also a research direction</li>
</ul>
</li>
<li><p>Package:</p>
<ul>
<li>to execute real time tasks on the edge, many pacages sacrifice memory to reduce latency, so how to tradeoff the latency and memory</li>
<li>how to implement a local training process with limited computing power</li>
<li>how to execute multiple tasks on a package in the meantime</li>
</ul>
</li>
<li>running environment:<ul>
<li>how to design a lightweight edge operating system with high availability</li>
</ul>
</li>
<li>hardware:<ul>
<li>whether there is any relationship between the processing speed and power</li>
<li>to evaluate how suitable the hardware system is for each specific EI application</li>
</ul>
</li>
</ol>
<p>然后文章举了一些具体的application的scenarios:</p>
<ul>
<li>video analytics in public safety</li>
<li>connected and automonous vehicles</li>
<li>smart homes</li>
<li>smart and connectred health</li>
</ul>
<p><br></p>
<h3 id="Swing-Swarm-computing-for-Mobile-Sensing"><a href="#Swing-Swarm-computing-for-Mobile-Sensing" class="headerlink" title="Swing: Swarm computing for Mobile Sensing"></a>Swing: Swarm computing for Mobile Sensing</h3><ul>
<li>ICDCS 2018</li>
<li>Google + IBM + DUKE</li>
</ul>
<p>这篇文章表现的又是另一个问题和另一种解决方法，他提出的针对的问题就是说比如我要处理实时的视频，在视频中识别face，我目前所有的手机设备都没法达到24 frame per second，这就导致了长延时等问题。然后传统的处理方法是说我进行一个computation offloading,比如说把数据发回cloud servers去算，或者说我写代码让设备中的DSP和GPU一起用起来，来增加算力。</p>
<p>文章表示我这边提出了另一个方式，考虑到我们现在用户会带越来越多的设备，包括智能手表、手机、电脑以及各种Iot设备，我能不能把这些闲置的算力用起来。因此我们就提出了SWing来把我们所有的移动设备协同起来，一起让他们计算实时数据的答案。这样就不用到云，也可以不强要求网络连接（可以是一个设备变成热点，或者wifi直连（我猜））</p>
<p><img src="/2019/10/06/edge-computing/16.png" width="100%"></p>
<p>整个过程为首先让那些没有装这个app的设备装app，然后一个设备发起master thread，其他变成worker thread。主thread广播自己的ip，等待连接，然后其他设备去主动连接主设备。然后主设备给每个设备分配各自作为什么功能节点，然后我们执行计算，根据workflow来依次做自己的计算并传递计算后的数据。</p>
<p>其实我个人感觉是和一个一对多或者多对多思想的wifi 直连比较相似的。</p>
<p><br></p>
<h3 id="BottleNet-A-Deep-Learning-Architecture-for-Intelligent-Mobile-Cloud-Computing-Services"><a href="#BottleNet-A-Deep-Learning-Architecture-for-Intelligent-Mobile-Cloud-Computing-Services" class="headerlink" title="BottleNet: A Deep Learning Architecture for Intelligent Mobile Cloud Computing Services"></a>BottleNet: A Deep Learning Architecture for Intelligent Mobile Cloud Computing Services</h3><ul>
<li>USC</li>
</ul>
<p>文章的主要思想就是在原有edge-device collaborative learning的架构上进行更改，原有的结构中我们把一个完整的DNN模型切分成一部分在device上，一部分在edge上，但是由于dnn一般前部分层的输出的的size都大于了原有的size，因此会有较多部分的layer在edge上做计算。作者就想能不能对device上最后一层的结果进行压缩，然后传给云端，这样节省了传输的压力，并且可以让更少的layer在device上计算，来加快计算效率。也就是如下图，device后进行压缩，传输，然后解压后在cloud上继续计算，可以认为是一个类似autoencoder的东西。</p>
<p><img src="/2019/10/06/edge-computing/17.png" width="60%"></p>
<p>然后在training中，可以认为是遍历了每个layer后不同的压缩情况，进行筛选出最合适的架构进行edge-device协同计算。</p>
<p><br></p>
<h3 id="BottleNet-An-End-to-End-Approach-for-Feature-Compression-in-Device-Edge-Co-Inference-Systems"><a href="#BottleNet-An-End-to-End-Approach-for-Feature-Compression-in-Device-Edge-Co-Inference-Systems" class="headerlink" title="BottleNet++: An End-to-End Approach for Feature Compression in Device-Edge Co-Inference Systems"></a>BottleNet++: An End-to-End Approach for Feature Compression in Device-Edge Co-Inference Systems</h3><ul>
<li>香港科大</li>
</ul>
<p>这篇是根据上面继续做的。他是把中间压缩解压部分变成了一个encoder+decoder再加上了一个channel。</p>
<p><img src="/2019/10/06/edge-computing/18.png" width="100%"></p>
<p>他和bottleNet主要的不同点在于BottleNet assumes reliable communication over the wireless channel and ignores the bandwidth expansion caused by channel coding。而bottleNet++考虑了channel condition，并且利用了DNN的fault-tolerance property。[感觉是加了一点信道的想法进去]</p>
<p>他整个网络的训练是，先训练本身的DNN，然后固定DNN的参数训练中间那个BottleNet++，然后最后一起调整【emm感觉这是一个很玄学的training方法，很容易崩掉吧应该。不是特别懂炼丹】</p>
<p><br></p>
<h3 id="JointDNN-An-Efficient-Training-and-Inference-Engine-for-Intelligent-Mobile-Cloud-Computing-Services"><a href="#JointDNN-An-Efficient-Training-and-Inference-Engine-for-Intelligent-Mobile-Cloud-Computing-Services" class="headerlink" title="JointDNN:An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services"></a>JointDNN:An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services</h3><ul>
<li>USC</li>
</ul>
<p>这篇文章也是研究collaborative learning的。研究如何在battery限制或energy consumption有限制或者云端有限制等各类情况下的一个collaborative方式。</p>
<p><img src="/2019/10/06/edge-computing/19.png" width="80%"></p>
<p>正常的DNN计算结构如图4所示，因为我们没有确定哪些层在cloud上计算，哪些层在device上计算，所以可以画出下面那个图，下面一排就是在device上，ME代表了这层在device上的计算时间，上面那层代表在cloud上算，CE代表了这层在云上计算的时间，然后如果要传输的话，再加上传输时间。</p>
<p>然后我们就根据图列出等式，计算communication和computation情况，然后加上对应的限制，转为一个ILP的问题。</p>
<p><br></p>
<h3 id="Overcoming-Forgetting-in-Federated-Learning-on-Non-IID-Data"><a href="#Overcoming-Forgetting-in-Federated-Learning-on-Non-IID-Data" class="headerlink" title="Overcoming Forgetting in Federated Learning on Non-IID Data"></a>Overcoming Forgetting in Federated Learning on Non-IID Data</h3><ul>
<li>NIPS 2019</li>
<li>Edgify</li>
</ul>
<p>全文翻译参考cd dalao的 blog<a href="https://www.cnblogs.com/lucifer1997/p/11814311.html" target="_blank" rel="noopener">https://www.cnblogs.com/lucifer1997/p/11814311.html</a></p>
<p>文章主要是解决了非i.i.d.情况下的联邦学习问题。他将联邦学习和终身学习进行类比，应用了灾难性遗忘的解决方案在联邦学习上，在损失函数中加上一个惩罚项，强迫所有的局部模型收敛道一个共享的最优值。</p>
<blockquote>
<p>联邦学习问题和另一个被称为终身学习的基本机器学习问题（以及相关的多任务学习）之间有着很深的相似性。在终身学习中，挑战是学习任务A，并使用相同的模型继续学习任务B，但不要“遗忘”，不要严重影响任务A的性能；或者一般来说，学习任务A1, A2, …依次进行，不要忘记以前学过的任务，这些任务不再提供样本。除了串行而不是并行的学习任务外，在终身学习中，每个任务只出现一次，而在联邦学习中则没有这样的限制。但撇开这些差异不谈，这些范式有一个共同的主要挑战——如何在不干扰在同一模型上学习的不同任务的情况下学习一项任务。</p>
</blockquote>
<blockquote>
<p>本文提出了一种新的终身学习算法——弹性权值合并（Elastic Weight Consolidation, EWC）。EWC旨在防止从学习任务A转移到学习任务B时发生灾难性遗忘。其思想是确定网络参数Θ中对任务A信息量最大的坐标，然后在学习任务B时，惩罚学习者更改这些参数。 它的基本假设是深度神经网络过参数化程度足够高，因此很有可能找到一个任务B的最优解在先前学习到的任务A的最优解的邻域。</p>
</blockquote>
<p><br></p>
<p>另外,还看了另一篇paper</p>
<h3 id="Asynchronous-Online-Federated-Learning-for-Edge-Device"><a href="#Asynchronous-Online-Federated-Learning-for-Edge-Device" class="headerlink" title="Asynchronous Online Federated Learning for Edge Device"></a>Asynchronous Online Federated Learning for Edge Device</h3><ul>
<li>under review of SDM 2020</li>
</ul>
<p>主要针对的是目前的Federated Learning是同步更新，会存在很多waiting时间，以及inter-client relatedness会不断的变化等问题，就提出用异步的方式进行更新，就收到一组就更新一组的做法（不太了解具体算法的精妙？）</p>
<p><img src="/2019/10/06/edge-computing/20.png" width="80%"></p>
<p><br></p>
<h3 id="TeamNet-A-Collaborative-Inference-Framework-on-the-Edge"><a href="#TeamNet-A-Collaborative-Inference-Framework-on-the-Edge" class="headerlink" title="TeamNet: A Collaborative Inference Framework on the Edge"></a>TeamNet: A Collaborative Inference Framework on the Edge</h3><ul>
<li>ICDCS 2019</li>
<li>McMaster U</li>
</ul>
<p>这篇文章的思想是，我edge只能放一些 shallow neural network，效果肯定不如deep neural network，那我能不能说我用多个edge一起来针对这个task，每个edge部分专门负责一部分的subset of dataset，也就是每个人术业有专攻，这样来针对整个任务，在edge上就能达到比较好的效果。（借用了mixture of experts的思想)</p>
<p>teamnet的整个思想就是说，我每个edge上是一个网络，然后我来一个数据，我把数据传到每个edge上，然后他们各自prediction的结果和他们的predictive的entropy。一个分布的entropy越大，我们对于这个分布的uncertainty越大。我们认为uncertainty越小，就越应该是对应的结果。也就是每次选择entropy最小的，作为对应的结果输出。[training部分还没有特别理解清楚，用到了再看吧]</p>
<p>过程图如下：</p>
<p><img src="/2019/10/06/edge-computing/21.png" width="100%"></p>
<p><br></p>
<h3 id="Learning-from-a-Teacher-using-Unlabeled-Data"><a href="#Learning-from-a-Teacher-using-Unlabeled-Data" class="headerlink" title="Learning from a Teacher using Unlabeled Data"></a>Learning from a Teacher using Unlabeled Data</h3><ul>
<li>Google AI</li>
<li>reject by NIPS 2019</li>
</ul>
<p>文章大概讲这么一个case，就是说我有一个teacher network，用我的数据集A去训练这个teacher network，然后我又有一堆无标签的和数据集A数据不同分布的数据集B，我利用数据集B和teacher network去train我的student network。train的方式是说minimize the cross-entropy of logits of teacher network and student network on B。</p>
<p>然后文章又说这样train出来的student模型用原来的数据集A做test，有比teacher network只低一点的acc，如果从A中取少量样本再fine tune一下student network，则student network的acc会高于原有的teacher network。</p>
<p>有个很迷惑的地方，感觉文章里面没有说的很清楚，但感觉他写的意思里面，teacher network和student network如果都是CNN或者都是MLP的情况下，架构是一样的，就没有谁比较大谁比较小的区分。感觉这样就很不solid？但是我感觉这个实验本身也有点迷惑，就感觉你用大量的无标注数据去让student network跟teacher network去学习一个网络的表示能力，然后回去测同一个数据集，我觉得理应acc差不多啊，<strong>唯一可以讨论的是，为什么再用少部分A去fine tune student network，他的acc会超过teacher network，在有些数据集情况下还会超过很多。</strong></p>
<p>然后对于我们而言，可以考虑的是我们在应用场景中也有很多的无标注数据，如果teacher network是work的话，也可以用文中的方法来利用unlabel dataset。</p>
<p>但是文中的阐述我觉得一方面虽然说是在说非同分布的unlabel的dataset可以帮助提高acc，但是感觉另一方面而言，我觉得应该看一下如果student network capacity相比于student network较小的情况下，能不能通过unlabel dataset来帮助这个小network 变得更为鲁棒呢？因为小网络的症结很容易是他的整个泛化能力就差很多，然后，鲁棒性也差很多，那我能不能用unlabel的network来帮助提高网络的质量呢？</p>
<p>有个问题，假设我们前面的过程都不变，如果用数据集C去测试teacher network和student network，会有什么结果，如果C和A同分布，如果和C和A不同分布，如果用少部分C去微调teacher 和student，然后再测试又会有什么结果?</p>
<blockquote>
<p>附带黄叔叔的博文：思考无标注数据的可用极限，给出了无标注数据的各种用法<a href="https://zhuanlan.zhihu.com/p/88742328深度好文，虽然我现在还没有能完全get到全部的sense" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/88742328深度好文，虽然我现在还没有能完全get到全部的sense</a> 2333</p>
</blockquote>
<p>另外</p>
<h3 id="Billion-scale-semi-supervised-learning-for-image-classification"><a href="#Billion-scale-semi-supervised-learning-for-image-classification" class="headerlink" title="Billion-scale semi-supervised learning for image classification"></a>Billion-scale semi-supervised learning for image classification</h3><p>来自19年Facebook的工作和上文非常类似，唯一不同的是，这边是用teacher根据数据集B（不一定）生成每个图片对应的标签，然后选择和数据集A相关的examples，来训练student network，然后再来fine tune student network。整个思路我觉得基本都是一样的，同样，结果也相差不多:</p>
<ul>
<li>fine tune是非常重要的，fine tune后整个network的结果是可以查过单纯supervised learning的acc的</li>
<li>当然teacher network和student network的capacity越强，acc越高，但是也是有上限的</li>
<li>讨论了student 和 teacher结构大小完全相同的情况下，就可以认为是一个self learning，这样的话也是可以提升acc的</li>
</ul>
<p>另外一篇文章</p>
<p><br></p>
<h3 id="Self-training-with-Noisy-Student-improves-ImageNet-classification"><a href="#Self-training-with-Noisy-Student-improves-ImageNet-classification" class="headerlink" title="Self-training with Noisy Student improves ImageNet classification"></a>Self-training with Noisy Student improves ImageNet classification</h3><ul>
<li>Google + CMU</li>
</ul>
<p>也是self-training的路子，整个标准的过程为：</p>
<ol>
<li>train a teacher model on labeled images</li>
<li>use the teacher to generate pseudo labels on unlabeled images</li>
<li>train a student model on the combination of labeled images and pseudo labeled images.</li>
</ol>
<p>然后作者是增加了一步“we iterate the algorithm a few times by treating the student as a teacher to generate new pseudo labels and train a new student.”来逐个生成多个student。并且pseudo labeled是用的soft label </p>
<p>另外作者在student model训练中加入了一些noise，包括了dropout,data arumentation,以及stochastic depth。另外作者认为大结构的网络的效果肯定超过小的网络，所以这边的student network size是大于teacher network。</p>
<p>整个训练以后，整个网络的acc提高，且在鲁棒性上的测试结果也有很大的提升。</p>
<blockquote>
<p>这连着三篇的基本思路或者工作内容都是一样的，利用self-training来提高模型的效果，也算是一种对unlabeled data的好的应用方式把。但是追根究底为什么这样能提高也是一个非常玄学的问题，我其实并没有明白这个高于原有的指导网络的acc是什么原有。</p>
<p>对于我们的小模型而言，如何有更为鲁棒的效果，我现在能想到的也是一个是利用更多的unlabeled data，一方面利用对抗的样本把。当然是不是说我们无脑的数据多就是可以提升效果呢？这也是一个很复杂的问题。</p>
</blockquote>
<p><br></p>
<h3 id="Are-All-Layers-Created-Equal"><a href="#Are-All-Layers-Created-Equal" class="headerlink" title="Are All Layers Created Equal?"></a>Are All Layers Created Equal?</h3><ul>
<li>Google</li>
</ul>
<p>有个很神奇又很主要的观点是：网络中可以分为重要的层和鲁棒的层，假设我们这个网络训练了N次，并且我记录了初始的网络参数，将训练完的网络中的一个鲁棒层参数替换为该层初始状态的网络参数，整个模型的acc基本不变，重要的层则更换后acc就崩了。另外这些鲁棒层的参数如果换成random的值，acc也会崩掉。</p>
<p><br></p>
<h3 id="Incremental-Learning-Using-a-Grow-and-Prune-Paradigm-with-Efficient-Neural-Networks"><a href="#Incremental-Learning-Using-a-Grow-and-Prune-Paradigm-with-Efficient-Neural-Networks" class="headerlink" title="Incremental Learning Using a Grow-and-Prune Paradigm with Efficient Neural Networks"></a>Incremental Learning Using a Grow-and-Prune Paradigm with Efficient Neural Networks</h3><ul>
<li>Princeton U</li>
</ul>
<p>文章讲述的是对一个网络在incremental的数据不断进入的时候做一个grow connection和prune connection的操作。这边是一个MLP在减connection的情况。</p>
<p>每一轮初，我的MLP都是稀疏的，也就是说我MLP中有些边是断掉的。然后每次的增减边都是根据当前epoch中每个边的gradient情况，gradient大的我就grow，小的就prune。【就算是断掉的边也可以计算gradient】</p>
<p>然后他就这样在每个epoch结束后增减边连接。然后因为是新数据进来，并且我们还要保有原有的数据的知识，他这边是先单独算新data，后面所有的data结合在一起算，这样来保证记忆和新知识。然后实验证明这个做法的效果好并且相比那些从头算起等的可以减少计算的epoch。 </p>
<p><br></p>
<h3 id="Large-Scale-Distributed-Neural-Network-Training-Through-Online-Distillation"><a href="#Large-Scale-Distributed-Neural-Network-Training-Through-Online-Distillation" class="headerlink" title="Large Scale Distributed  Neural Network Training Through Online Distillation"></a>Large Scale Distributed  Neural Network Training Through Online Distillation</h3><ul>
<li>Google + Hilton</li>
<li>2018</li>
</ul>
<p>主要想法其实就是说我在学习的过程中，可以有多个student一起学习，大家互相分享学习到的结果。也就是说这边不是像那些异步SGD一样，利用每个人学习到的gradient参数进行整合，而是大家分享自己学习到的结果，也就是对于同一个数据，我们不仅仅获得对应数据集的标签，另外还会去了解同学对这个数据集学到的结果，一起来帮助我们学习。就像我们平时自己学习一样，同学之间互相交流对一个问题的理解能让我们更好的理解问题。</p>
<p>这边也就是这个思想，然后来证明了可以再更短的step中有一个好的acc表现（你都多个人一起学了，还不能学快点不是在搞笑么？）</p>
<blockquote>
<p>目前的蒸馏思想会改变在federated learning里面说我都上传梯度的思想，也是可以上传对同一数据集的结果，来指导大家学习。</p>
</blockquote>
<p><br></p>
<h3 id="Deep-Mutual-Learning"><a href="#Deep-Mutual-Learning" class="headerlink" title="Deep Mutual Learning"></a>Deep Mutual Learning</h3><ul>
<li>CVPR 2017 最佳学生论文</li>
</ul>
<blockquote>
<p>该论文探讨了一种与模型蒸馏(model distillation)相关却不同的模型—即相互学习(mutual learning)。 蒸馏从一个强大的大型预训练教师网络开始，并向未经训练的小型学生网络进行单向知识转移。 相反，在相互学习中，我们从一群未经训练的学生网络开始，他们同时学习一起解决任务。 具体来说，每个学生网络都有两个的损失函数：一种传统的监督性损失函数，以及一种模仿性的损失函数(mimicry loss)，使每个学生的后验概率分布与其他学生的类别概率保持一致。</p>
<p>通过这种方式进行训练，结果表明，在这种基于同伴教学(peer-teaching)的情景中，每个学生的学习都比在传统的监督学习方案中单独学习要好得多。 此外，以这种方式训练的学生网络比来自更大的预训练教师的传统蒸馏训练的学生网络获得更好的结果。论文实验表明，各种网络架构可以从相互学习中受益，并在CIFAR-100识别和Market-1501 ReID 数据集上获得令人信服的结果。</p>
<p>通常情况下有很多的解决方案能够让训练误差变为0，然而有些解决方法的泛化能力要强一点。因为梯度下降法找打的最优点不是在狭小的谷底内，而是在宽阔的峡谷中，当我们加入相对熵以后能够让网络找到更小的值，从而实现更优的结果。</p>
</blockquote>
<p>解读链接<a href="https://www.cnblogs.com/nowgood/p/DeepMutualLearning.html" target="_blank" rel="noopener">https://www.cnblogs.com/nowgood/p/DeepMutualLearning.html</a></p>
<p><a href="https://www.cnblogs.com/SuperLab/p/10750486.html" target="_blank" rel="noopener">https://www.cnblogs.com/SuperLab/p/10750486.html</a></p>
<p><br></p>
<h3 id="FedMD-Heterogenous-Federated-Learning-via-Model-Distillation"><a href="#FedMD-Heterogenous-Federated-Learning-via-Model-Distillation" class="headerlink" title="FedMD: Heterogenous Federated Learning via Model Distillation"></a>FedMD: Heterogenous Federated Learning via Model Distillation</h3><ul>
<li>Harvard, Yale</li>
<li>Nips 2019</li>
</ul>
<p>这篇文章主要的想法就是说，我能支持我每个device的网络都不是一样的，然后每个人有自己的个人的private dataset，然后我们共有一个public 的dataset，然后我们的所有dataset的分布都可能是iid或者non iid的，然后就想用transfer learning + knowledge distillation来是的我们自己的device的网络也不断的更新，并且拥有不错的表现。</p>
<p>方法的过程就是：</p>
<ol>
<li>我根据public的数据训练每个device的网络，然后利用transfer learning迁移到我对应的private dataset上，修改我的网络</li>
<li>然后每一个周期，我们随机从public 的dataset里面抽取一定量的dataset，然后每个device自己计算这个dataset的结果，然后一起发到云端，然后云端做一个求平均和以后发给每个device，每个device根据这个平均和结果去调整自己的网络。调整的过程是通过蒸馏学习的思想进行指导我的网络调整的。</li>
</ol>
<p>然后他实验拿了minst/Feminst和cifar10/cifar100来做，证明了在iid和非iid下这种federated learning都会有提升。感觉这个实验非常的不solid，你增加了训练样本，当然会提高acc，感觉应该跟别的场景进行对比，证明他比其他的框架下的提升多？</p>
<p>这边的亮点就说我可以支持你们网络结构不一样，以平均和的思想来提出目标结果，来指导大家学习。但是首先，private dataset预先不可能知道的，大概率也不会有label的，他这个应该更像是说我几个大平台上已经有数据了，来提升我自己的模型的一个办法，而不是说我不断应用的一个场景，场景不同，面对他的场景，我觉得还是说的很有道理的。果真distillation是个很好的东西。我应该思考一下这些怎么用进去。</p>
<p>当然non iid明显效果还是在波动的，所以说其实我觉得肯定是要和而不同的。</p>
<p><br></p>
<p>插播一个摘要，留着备用</p>
<blockquote>
<p>Domain Adaption approaches proposed over the past decade include discrepancy-based methods, reconstruction-based UDA models and adversary-based approaches.</p>
</blockquote>
<p><br></p>
<h3 id="Federated-Learning-in-Mobile-Edge-Networks-A-Comprehensive-Survey"><a href="#Federated-Learning-in-Mobile-Edge-Networks-A-Comprehensive-Survey" class="headerlink" title="Federated Learning in Mobile Edge Networks: A Comprehensive Survey"></a>Federated Learning in Mobile Edge Networks: A Comprehensive Survey</h3><ul>
<li>2019 IEEE fellow</li>
</ul>
<p>论文翻译贴：<a href="https://blog.csdn.net/liuxixi920/article/details/102805188" target="_blank" rel="noopener">https://blog.csdn.net/liuxixi920/article/details/102805188</a></p>
<p><br></p>
<h3 id="Federated-Learning-with-Non-IID-Data"><a href="#Federated-Learning-with-Non-IID-Data" class="headerlink" title="Federated Learning with Non-IID Data"></a>Federated Learning with Non-IID Data</h3><ul>
<li>Arm 2018</li>
</ul>
<p>他这边主要的思想是提出了如何解决在federated learning中应对non iid问题。最普遍的convergence方法是Fedavg，他用实验说明FedAvg在non iid数据集上表现很差，然后他让标准SGD方法，iid下的fed avg，2class的non iid和1class的non iid的四种情况在同一初始化的网络上训练，然后发现每一层的参数的距离中有比较大的差距，这边以sgd为标准，iid下的网络参数和他非常接近，而non iid的参数则相差很多，尤其是1 class的non iid情况。</p>
<p>然后作者就提出了说我的acc效果和我参数的weight divergence是相关的，weight divergence越小，我的acc表现越好，然后他又证明了这个weight divergence的程度可以用EMD这个matrix来衡量，并且用实验证明说，我的test结果随emd的值增加而降低，且在emd较小的时候，acc掉的很少，到一个阈值以后开始掉的比较多。</p>
<p>所以作者提出说为了让我这个emd小，我就从我原有给中心训练初始network的数据集里面分一点出来发给每个device做一部分training data，来减小我每个device中数据集分布的差异，从而减少我每个数据集之间的emd值，这样提高我的整体acc。</p>
<p>实验证明效果还是很不错的，然后你共享多少程度的training data就是一个communication和acc的trade off。</p>
<blockquote>
<p>但是感觉就是加了一点共享的数据，这就是降低了iid的程度，自然就是效果好了把，我觉得还挺显然的，也没有从根本解决问题。</p>
</blockquote>
<p><br></p>
<h3 id="MetaPruning-Meta-Learning-for-Automatic-Neural-Network-Channel-Pruning"><a href="#MetaPruning-Meta-Learning-for-Automatic-Neural-Network-Channel-Pruning" class="headerlink" title="MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning"></a>MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning</h3><ul>
<li>旷视 2019 ICCV</li>
</ul>
<p>文章提出训练一个pruneNet，然后给这个net输入每层的channel数，他会生成对应这个结构下work的网络，然后在测试集上验证这个网络的效果。所以也就是我们要找出最合适的每层的channel数，这个寻找的过程，他利用的是进化算法来搜索。</p>
<p>整个文章的基础想法基于剪枝网络权重不重要，重要的是网络的结构。</p>
<p>他人的blog：</p>
<ul>
<li><a href="https://www.jianshu.com/p/be3054560315" target="_blank" rel="noopener">https://www.jianshu.com/p/be3054560315</a></li>
<li><a href="https://xmfbit.github.io/2019/10/26/paper-meta-pruning/" target="_blank" rel="noopener">https://xmfbit.github.io/2019/10/26/paper-meta-pruning/</a></li>
</ul>
<p><br></p>
<h3 id="Online-Knowledge-Distillation-with-Diverse-Peers"><a href="#Online-Knowledge-Distillation-with-Diverse-Peers" class="headerlink" title="Online Knowledge Distillation with Diverse Peers"></a>Online Knowledge Distillation with Diverse Peers</h3><ul>
<li>AAAI 2020</li>
<li>ZJU</li>
</ul>
<p>文章主要讨论的是，我没有一个预训练好的teacher model的时候，我能不能通过多个student network互相学习来学出一个很好的模型，这和上面有一篇文章的思想是类似的，文章不一样的地方主要是强调了每个学生网络的diversity，来避免很快的convergence，来学到更多的知识。</p>
<p>整个distillation的过程包括了三个步骤，假设我现在一共有m个network，我让第m个成为leader，其他都是普通的network。这边的loss function包含了三个部分，一个是hard label的diff。</p>
<p>然后第一部分的loss就来自我的普通network们，然后我对每个network算出一个他的soft label，计算的方法是普通网络的soft label的加权和，权重是通过类似attention的思想搞出来的。也就是说每个网络的target soft label是不同的，但又是结合了大家的信息的，然后所以这样的学习会导致他们学的有diversity。然后利用每个target和自身的label的kl散度×t^2,组成了第二部分的loss function。</p>
<p>第二个部分就是所有普通网络的soft label的平均就是leader network的target soft label，然后再求一个kl散度，就是第三部分的loss。</p>
<p>然后训练结束后，就选用leader进行部署就可以了。</p>
<p>实验部分他就证明了他的效果好于别的distillation方法。但是如果给这个方法上添加一个teacher network，效果会更好。</p>
<blockquote>
<p>疑惑，就为什么要有这个leader的角色呢，没有的话效果会差多少呢？是为了选择的方便么？还是说他扮演这一个结合所有人信息量的思想</p>
<p>以及为什么是一个attention的方法分配权重，是更多的像自己相近的人学习么，还是怎么样一个权重的解释呢</p>
<p>感觉现在越来越多的paper在做一个多student的模型，但是多student的时间训练时间很长？当然也不一定，因为可以有一个并行student训练的过程，来相比有teacher节省时间把。</p>
<p>然后在多student的模型中，有个非常重要的点就是如何保证他的diversity性，来帮助他更好的学习不同方面的知识内容。</p>
<p>对于我而言的话，就是说我能不能给他找一个在边缘中的应用场景。或者利用他的地方，比如在personalized的地方利用这个diversity 的student的思想。</p>
</blockquote>
<p><br></p>
<p>####　突如其来的思路：</p>
<p>有个非常常见的应用场景，我们云端有一个很牛逼的大网络了，现在需要给用户提供一个适配他容量等的小网络，然后用户会提供给我们一些非常少的数据，代表了他的数据分布，比如语音助手里面，可以让用户说两句指定的话，人脸识别里面会先提供自己的人脸，所以也就是有用户提供的少量的正例样本数据。然后我们根据这些正例样本数据结合我原有的训练本身的大网络的模型，去做一个针对用户的压缩，这个压缩不需要适配原有的数据分布，而是会靠近用户特定的数据分布。</p>
<p>然后我们先做这样一个特定的压缩，提供用户个性化的压缩网络。这能不能算一个问题？</p>
<p>主要的点是：</p>
<ol>
<li>我不需要适应一个大的分布</li>
<li>我有微量的数据</li>
<li>我需要的是针对性的压缩，而不是普世的压缩。</li>
</ol>
<p>然后我根据说我针对性的压缩后，得到了多个针对不同用户的小网络，然后他们各自工作，获得一些没有label的数据，我们再考虑如何利用这些unlabeled的数据优化我们的网络。比如带有权重的samples进行训练。</p>
<p><br></p>
<h3 id="Federated-Learning-with-Personalization-Layers"><a href="#Federated-Learning-with-Personalization-Layers" class="headerlink" title="Federated Learning with Personalization Layers"></a>Federated Learning with Personalization Layers</h3><ul>
<li>Adobe</li>
<li>Under 2020 AISTATS</li>
</ul>
<p>主要的想法就是用来应对(statistical heterogeneity,他是说的这个，但是明明讲的是异质性啊啊啊)，就是大家数据分布不同的意思 吧我觉得是这样的，然后他就说那我们每个 device共享前几层base的layer，后面几层用自己的personalized layer，这样来保证大家的独特性。</p>
<p>然后我更新的方式就是说，我首先从云端拿最新的base layer 的权重，然后根据这个权重，以及我本身的personalized layer的权重，来根据我的数据调整自己的base layer权重 和personalized 的权重 ，然后我获得我新的personalized的权重 ，然后我们每个device将自己新的base layer权重扔到云端上去，average一个新的base  layer的 权重。</p>
<p>后续他做了几个实验，和fedavg对比（只和fedavg对比也太emm了 ），就是说限制我每个device拿到的数据的类别，比如说我cifar10，就限制每个device只能搞到4 class的data或者8类或者 10类（10类就是最原始的情况了），然后说这个方法比那个好很多（看图的确好很多，但是为什么连10类都是好的呢？）挠头 ，如果 要我解释的话，我觉得应该是增加了数据的多样性，更好的进行一个学习和碰撞？</p>
<p>不过感觉说做personalized的，最基本的思想就是base+personalized了。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/22/Cloud/" rel="next" title="云相关知识">
                <i class="fa fa-chevron-left"></i> 云相关知识
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/12/02/6-828/" rel="prev" title="6.828课程学习">
                6.828课程学习 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
     <div id="gitalk-container"></div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">yunyan.hong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Neurosurgeon-Collaborative-Intelligence-Between-the-Cloud-and-Mobile-Edge"><span class="nav-number">1.</span> <span class="nav-text">Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distributed-Deep-Neural-Networks-over-the-Cloud-the-Edge-and-End-Devices"><span class="nav-number">2.</span> <span class="nav-text">Distributed Deep Neural Networks over the Cloud, the Edge and End Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Big-Little-Deep-Neural-Network-for-Ultra-Low-Power-Inference"><span class="nav-number">3.</span> <span class="nav-text">Big/Little Deep Neural Network for Ultra Low Power Inference</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Cascading-Neural-Network-Building-the-Internet-of-Smart-Things"><span class="nav-number">4.</span> <span class="nav-text">The Cascading Neural Network: Building the Internet of Smart Things</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Edge-Intelligence-Paving-the-Last-Mile-of-Artificial-Intelligence-with-Edge-Computing"><span class="nav-number">5.</span> <span class="nav-text">Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BranchyNet-Fast-Inference-via-Early-Exiting-from-Deep-Neural-Networks"><span class="nav-number">6.</span> <span class="nav-text">BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#distilling-the-Knowledge-in-a-Neural-Network"><span class="nav-number">7.</span> <span class="nav-text">distilling the Knowledge in a Neural Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Acceleration-for-General-Purpose-Approximate-Programs-2012"><span class="nav-number">8.</span> <span class="nav-text">Neural Acceleration for General-Purpose Approximate Programs(2012)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prediction-Based-Quality-Control-for-Approximate-Accelerators-2015"><span class="nav-number">9.</span> <span class="nav-text">Prediction-Based Quality Control for Approximate Accelerators(2015)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Born-Again-Neural-Networks"><span class="nav-number">10.</span> <span class="nav-text">Born-Again Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Rocket-Launching-A-Universal-and-Efficient-Framework-for-Training-Well-performing-Light-Net"><span class="nav-number">11.</span> <span class="nav-text">Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Collaborative-Learning-between-Cloud-and-End-Devices-An-Empirical-Study-on-Location-Prediction"><span class="nav-number">12.</span> <span class="nav-text">Collaborative Learning between Cloud and End Devices: An Empirical Study on Location Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications"><span class="nav-number">13.</span> <span class="nav-text">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices"><span class="nav-number">14.</span> <span class="nav-text">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ThiNet-A-Filter-Level-Pruning-Method-for-Deep-Neural-Network-Compreesion"><span class="nav-number">15.</span> <span class="nav-text">ThiNet: A Filter Level Pruning Method for Deep Neural Network Compreesion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Snapshot-Distillation-Teacher-Student-Optimization-in-One-Generation"><span class="nav-number">16.</span> <span class="nav-text">Snapshot Distillation: Teacher-Student Optimization in One Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SeerNet-Predicting-Convolutional-Neural-Network-Feature-Map-Sparsity-through-Low-Bit-Quantization"><span class="nav-number">17.</span> <span class="nav-text">SeerNet: Predicting Convolutional Neural  Network Feature-Map Sparsity through Low-Bit Quantization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GOOGLE-Federated-Learning-Papers"><span class="nav-number">18.</span> <span class="nav-text">GOOGLE Federated Learning Papers:</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Applied-Federated-learning-Improving-Google-Keyborad-Query-Suggestions"><span class="nav-number">18.0.1.</span> <span class="nav-text">Applied Federated learning: Improving Google Keyborad Query Suggestions</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Federated-Learning-For-Mobile-Keyboard-Prediction"><span class="nav-number">18.0.2.</span> <span class="nav-text">Federated Learning For Mobile Keyboard Prediction</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Federated-Learning-Of-Out-Of-Vocabulary-Words"><span class="nav-number">18.0.3.</span> <span class="nav-text">Federated Learning Of Out-Of-Vocabulary Words</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Towards-Federated-Learning-At-Scale-System-Design"><span class="nav-number">18.0.4.</span> <span class="nav-text">Towards Federated Learning At Scale: System Design</span></a></li></ol></li></ol><li class="nav-item nav-level-3"><a class="nav-link" href="#In-situ-AI-Towards-Autonomous-and-Incremental-Deep-Learning-for-IoT-Systems"><span class="nav-number">19.</span> <span class="nav-text">In-situ AI : Towards Autonomous and Incremental Deep Learning for IoT Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#新的思考part"><span class="nav-number">20.</span> <span class="nav-text">新的思考part</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Task-Adaptive-Incremental-Learning-for-Intelligent-Edge-Devices"><span class="nav-number">21.</span> <span class="nav-text">Task-Adaptive Incremental Learning for Intelligent Edge Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distilling-Critical-Paths-in-Convolutional-Neural-Networks"><span class="nav-number">22.</span> <span class="nav-text">Distilling Critical Paths in Convolutional Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Orchestrating-Development-Lifecycle-of-Machine-Learning-Based-IoT-Applications-A-Survey"><span class="nav-number">23.</span> <span class="nav-text">Orchestrating Development Lifecycle of Machine Learning Based IoT Applications: A Survey</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ReForm-Static-and-Dynamic-Resource-Aware-DNN-Reconfiguration-Framework-for-Mobile-Device"><span class="nav-number">24.</span> <span class="nav-text">ReForm: Static and Dynamic Resource-Aware DNN Reconfiguration Framework for Mobile Device</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobiEye-An-Efficient-Cloud-based-Video-Detection-System-for-Real-time-Mobile-Applications"><span class="nav-number">25.</span> <span class="nav-text">MobiEye: An Efficient Cloud-based Video Detection System for Real-time Mobile Applications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#An-Optimized-Design-Technique-of-Low-bit-Neural-Network-Training-for-Personalization-on-IoT-Devices"><span class="nav-number">26.</span> <span class="nav-text">An Optimized Design Technique of Low-bit Neural Network Training for Personalization on IoT Devices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Context-Aware-Convolutional-Neural-Network-Over-Distributed-System-in-Collaborative-Computing"><span class="nav-number">27.</span> <span class="nav-text">Context-Aware Convolutional Neural Network Over Distributed System in Collaborative Computing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Machine-Learning-at-Facebook-Understanding-Inference-at-the-Edge"><span class="nav-number">28.</span> <span class="nav-text">Machine Learning at Facebook: Understanding Inference at the Edge</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CAPTOR-A-Class-Adaptive-Filter-Pruning-Framework-for-Convolutional-Neural-Networks-in-Mobile-Applications"><span class="nav-number">29.</span> <span class="nav-text">CAPTOR: A Class Adaptive Filter Pruning Framework for Convolutional Neural Networks in Mobile Applications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ApDeepSense-Deep-Learning-Uncertainty-Estimation-Without-the-Pain-for-IoT-Application"><span class="nav-number">30.</span> <span class="nav-text">ApDeepSense: Deep Learning Uncertainty Estimation Without the Pain for IoT Application</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenEI-An-Open-Framework-for-Edge-Intelligence"><span class="nav-number">31.</span> <span class="nav-text">OpenEI: An Open Framework for Edge Intelligence</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Swing-Swarm-computing-for-Mobile-Sensing"><span class="nav-number">32.</span> <span class="nav-text">Swing: Swarm computing for Mobile Sensing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BottleNet-A-Deep-Learning-Architecture-for-Intelligent-Mobile-Cloud-Computing-Services"><span class="nav-number">33.</span> <span class="nav-text">BottleNet: A Deep Learning Architecture for Intelligent Mobile Cloud Computing Services</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BottleNet-An-End-to-End-Approach-for-Feature-Compression-in-Device-Edge-Co-Inference-Systems"><span class="nav-number">34.</span> <span class="nav-text">BottleNet++: An End-to-End Approach for Feature Compression in Device-Edge Co-Inference Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JointDNN-An-Efficient-Training-and-Inference-Engine-for-Intelligent-Mobile-Cloud-Computing-Services"><span class="nav-number">35.</span> <span class="nav-text">JointDNN:An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Overcoming-Forgetting-in-Federated-Learning-on-Non-IID-Data"><span class="nav-number">36.</span> <span class="nav-text">Overcoming Forgetting in Federated Learning on Non-IID Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Asynchronous-Online-Federated-Learning-for-Edge-Device"><span class="nav-number">37.</span> <span class="nav-text">Asynchronous Online Federated Learning for Edge Device</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TeamNet-A-Collaborative-Inference-Framework-on-the-Edge"><span class="nav-number">38.</span> <span class="nav-text">TeamNet: A Collaborative Inference Framework on the Edge</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning-from-a-Teacher-using-Unlabeled-Data"><span class="nav-number">39.</span> <span class="nav-text">Learning from a Teacher using Unlabeled Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Billion-scale-semi-supervised-learning-for-image-classification"><span class="nav-number">40.</span> <span class="nav-text">Billion-scale semi-supervised learning for image classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Self-training-with-Noisy-Student-improves-ImageNet-classification"><span class="nav-number">41.</span> <span class="nav-text">Self-training with Noisy Student improves ImageNet classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Are-All-Layers-Created-Equal"><span class="nav-number">42.</span> <span class="nav-text">Are All Layers Created Equal?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Incremental-Learning-Using-a-Grow-and-Prune-Paradigm-with-Efficient-Neural-Networks"><span class="nav-number">43.</span> <span class="nav-text">Incremental Learning Using a Grow-and-Prune Paradigm with Efficient Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Large-Scale-Distributed-Neural-Network-Training-Through-Online-Distillation"><span class="nav-number">44.</span> <span class="nav-text">Large Scale Distributed  Neural Network Training Through Online Distillation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-Mutual-Learning"><span class="nav-number">45.</span> <span class="nav-text">Deep Mutual Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FedMD-Heterogenous-Federated-Learning-via-Model-Distillation"><span class="nav-number">46.</span> <span class="nav-text">FedMD: Heterogenous Federated Learning via Model Distillation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Federated-Learning-in-Mobile-Edge-Networks-A-Comprehensive-Survey"><span class="nav-number">47.</span> <span class="nav-text">Federated Learning in Mobile Edge Networks: A Comprehensive Survey</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Federated-Learning-with-Non-IID-Data"><span class="nav-number">48.</span> <span class="nav-text">Federated Learning with Non-IID Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MetaPruning-Meta-Learning-for-Automatic-Neural-Network-Channel-Pruning"><span class="nav-number">49.</span> <span class="nav-text">MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Online-Knowledge-Distillation-with-Diverse-Peers"><span class="nav-number">50.</span> <span class="nav-text">Online Knowledge Distillation with Diverse Peers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Federated-Learning-with-Personalization-Layers"><span class="nav-number">51.</span> <span class="nav-text">Federated Learning with Personalization Layers</span></a></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yunyan.hong</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '214b2aee446518ccee23',
          clientSecret: '6b5e9007abf73fbcdce7d46cc4ae66a5fa5e6a3d',
          repo: 'hongyunyan.github.io',
          owner: 'hongyunyan',
          admin: ['hongyunyan'],
          id: location.pathname,
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>



  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
